{"cells":[{"cell_type":"markdown","source":["# Phase 3:\n\n#### Team 14: Carlos Moreno, Elizabeth Khan, Jagan Lakshmipathy, and Ziling Huang\n\n__PIPELINE TESTING:__  \n\n**For more detail on EDA work please see the following notebook:**  \n``````\n\n**For more detail on JOIN WORK please see the following notebook:**\n``````"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51bbfb27-4bf5-4b85-838d-2cb459f74cc5"}}},{"cell_type":"markdown","source":["### PIPELINE"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c2edc36-8cc7-4d64-8083-c8be0544c3b7"}}},{"cell_type":"markdown","source":["#### 1. Setup and import libraries"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08118552-0b72-4f16-bc83-7704baf4beae"}}},{"cell_type":"code","source":["from pyspark.sql.functions import *\nimport pyspark.sql.functions as F\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom graphframes import *\nimport geopandas as gpd\nimport plotly as plotly\n\n# import custom cv module - for Custome Cross Validation - Timeseries\nspark.sparkContext.addPyFile(\"dbfs:/custom_cv.py\")\nfrom custom_cv import CustomCrossValidator\n\npd.set_option(\"display.max_rows\", 999)\npd.set_option(\"display.max_columns\", 200)\n\n#Import for implementing upsampling or downsampling\nfrom pyspark.sql.functions import col, explode, array, lit\n\n#from heatmap import heatmap, corrplot\nfrom pyspark.ml import *\nfrom pyspark.ml.linalg import *\nfrom pyspark.ml.stat import *\nfrom pyspark.ml.feature import *\nfrom pyspark.sql.window import *\n\n# Append weights to the dataset\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.functions import when\n\n# ML related libraries\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\nfrom pyspark.ml.feature import MinMaxScaler\nfrom pyspark.ml.feature import StandardScaler, Imputer\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.classification import LinearSVC\n\nfrom pyspark.mllib.evaluation import BinaryClassificationMetrics\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.mllib.evaluation import MulticlassMetrics\n\nfrom pyspark.ml.linalg import Vectors\nfrom itertools import combinations\n\n#Blob credentials\nblob_container = \"cemgr14c\" # The name of your container created in https://portal.azure.com\nstorage_account = \"cemgr14\" #The name of your Storage account created in https://portal.azure.com\nsecret_scope = \"w261gr14\" # The name of the scope created in your local computer using the Databricks CLI\nsecret_key = \"keygr14\" # The name of the secret key created in your local computer using the Databricks CLI\nblob_url = f\"wasbs://{blob_container}@{storage_account}.blob.core.windows.net\"\nmount_path = \"/mnt/mids-w261\"\n\n# SAS Token\n\nspark.conf.set(\n  f\"fs.azure.sas.{blob_container}.{storage_account}.blob.core.windows.net\",\n  dbutils.secrets.get(scope = secret_scope, key = secret_key)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ebba7419-84a4-4569-9031-02f9ab71eed4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 2. Functions to Evaluate Models \n##### Accuracy, Recall, Precision, F1_score, F2_score, F05_Score"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b503ebca-63bc-498d-94e6-7c6780bb94fd"}}},{"cell_type":"code","source":["# Helping Functions for Evaluating Models\ndef extract(row):\n  '''\n  Input: row with probability field combined.\n  Output: row with probability fiedl split.\n  '''\n  return (row.DEP_DEL15,) + tuple(row.probability.toArray().tolist()) +  (row.label,) + (row.prediction,)\n\ndef score(model,data):\n  pred = model.transform(data).select(\"DEP_DEL15\", \"probability\", \"label\", \"prediction\")\n  pred = pred.rdd.map(extract).toDF([\"DEP_DEL15\", \"p0\", \"p1\", \"label\", \"prediction\"])\n  return pred "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8cd5463e-3f8e-445b-8dc7-1fb5a8577640"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def model_metric(prediction):\n  '''\n  Input: precition dataframe including label and prediction.\n  Output: dictionary with key metrics (acccuracy: value, recall: value, ...)\n  This implementation uses map-reduce approach to calculating the metrics - created to facilitate calcuation with very large datasets.\n  '''\n  \n  # To emit pairs for counting the number of TP, TN, FP and FN in the dataset\n  def counts(label, pred):\n    \n    if (label == pred) and (label == 1.0): return ('TP', 1)\n    elif (label == pred) and (label != 1.0): return ('TN', 1)\n    elif (label != pred) and (label != 1.0): return ('FP', 1)\n    elif (label != pred) and (label == 1.0): return ('FN', 1)\n  \n  # Based on counts, it calculates the performance metrics\n  def cmetrics(counts):\n    \n    # Initialize variables, and convert counts to an array of tuples\n    TP, TN, FP, FN = 0.0, 0.0, 0.0, 0.0\n    carray = np.array(counts.collect())\n    metric_dic = {}\n    \n    # Extract the counts from the arry of tuples\n    for c in carray:\n      if c[0] == 'TP': TP = float(c[1])\n      elif c[0] == 'TN': TN = float(c[1])\n      elif c[0] == 'FP': FP = float(c[1])\n      elif c[0] == 'FN': FN = float(c[1])\n  \n    #print(TP, TN, FP, FN)\n    metric_dic[\"Accuracy\"] = (TP+TN) / (TP + TN + FP + FN)\n\n    if (TP+FP) != 0:\n      precision = TP/(TP+FP)\n      metric_dic[\"Precision\"] = precision\n    else:\n      precision = \"NA\"\n      metric_dic[\"Precision\"] = precision\n\n    if (TP+FN) != 0: \n      recall = TP/(TP+FN)\n      metric_dic[\"Recall\"] = recall\n    else:\n      recall = \"NA\"\n      metric_dic[\"Recall\"] = recall\n\n    if (TN+FP) != 0: metric_dic[\"Specificity\"] = TN/(TN+FP)\n    else: metric_dic[\"Specificity\"] = \"NA\"\n\n    if recall != \"NA\" and precision != \"NA\":\n      if (recall + precision) != 0:\n        metric_dic[\"F1_Score\"] = 2*(recall * precision) / (recall + precision)\n        beta = 0.5\n        metric_dic[\"F05_Score\"] = (1+beta**2)*(recall * precision) / ((beta**2 * precision) + recall)\n        beta = 2\n        metric_dic[\"F2_Score\"] = (1+beta**2)*(recall * precision) / ((beta**2 *precision) + recall)      \n      else: \n        metric_dic[\"F1_Score\"] = \"NA\"\n        metric_dic[\"F05_Score\"] = \"NA\"\n        metric_dic[\"F2_Score\"] = \"NA\"\n    else:\n      metric_dic[\"F1_Score\"] = \"NA\"\n      metric_dic[\"F05_Score\"] = \"NA\"\n      metric_dic[\"F2_Score\"] = \"NA\"\n        \n    return metric_dic    \n      \n  counts = prediction.rdd.map(lambda x: counts(x[3],x[4])) \\\n                         .reduceByKey(lambda x, y: x+y).cache()\n  \n  metrics = cmetrics(counts)\n  \n  return counts, metrics"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"872b071e-0e9a-4bdd-be10-c8a3f77ffda0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def metricsdf(dfdata, names):\n  '''\n  Input: \n     dfdata: list of dataframes with predictions and labels\n     names: name for model to be assigned to final metrics output.\n     \n   Output: dataframe with the metrics for each dataframe included in the list.\n  '''\n  \n  df_data = {}\n  \n  for df, name in zip(dfdata, names):\n    c, MetMod = model_metric(df)\n    df_data[name] = list(MetMod.values())\n\n  metrics = list(MetMod.keys())\n  dfM = pd.DataFrame(df_data, index = metrics)\n  \n  return dfM"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"25578036-de54-43ba-a85a-cdf3a8926dcc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def metricsdf2(metrics):\n  '''\n  Input: dataframe with label and predictions.\n  Output: dictionary with all relevant metrics calculated from the input dataframe.\n  This implementation uses the PySpark metrics implementation.\n  '''\n     \n  dfmetric = {}\n  recall = metrics.recall(1.0)\n  precision = metrics.precision(1.0)\n  dfmetric[\"Accuracy\"] = metrics.accuracy\n  dfmetric[\"Precision\"] = precision\n  dfmetric[\"Recall\"] = recall\n  if (recall + precision) != 0:\n    dfmetric[\"F1_Score\"] = 2*(recall * precision) / (recall + precision)\n  beta = 0.5\n  if ((beta**2 * precision) + recall) != 0:\n    dfmetric[\"F05_Score\"] = (1+beta**2)*(recall * precision) / ((beta**2 * precision) + recall)\n  beta = 2\n  if ((beta**2 *precision) + recall) != 0:\n    dfmetric[\"F2_Score\"] = (1+beta**2)*(recall * precision) / ((beta**2 *precision) + recall)\n  \n  return dfmetric"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97afe866-92ae-4fc9-ba36-b98b0b924c6b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Function to get distinct values of a dataframe for the categorical variables\ndef distinctvals(df, categoricals):\n  \n  '''\n  Input: \n    df: dataframe with all variables.\n    categoricals: name of categorical variables in the dataframe\n  Output: dictionary with list of categorical variables and the number of levels for each categorical variable.\n    \n  '''\n  \n  dv = {}\n  for colN in categoricals:\n    d = np.array(df.select(colN).distinct().collect())\n    dv[colN] = len(d)\n  \n  return dv"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"115f5c01-cd9a-4e58-9922-1921f14cb62d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def numattributes(df, categoricals, numerics):\n  '''\n  Input:\n    df: dataframe with attributes as columns.\n    categoricals: list of all categorical variables in dataframe\n    numerics: list of all numberical variables in dataframe\n  Output:\n    Number of variables in dataframe where each level for a categorical variable count as one, while each numeric\n    variable count as one.\n  '''\n  sum = 0\n  for f in categoricals:\n    d = np.array(df.select(f).distinct().collect())\n    sum += len(d)\n  return sum\n\n# nfeatures = numattributes(train_val, categoricals, numerics)\n# print(nfeatures)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a211ae43-de2c-4e2d-904a-fa417126cd46"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 3. Read Joined Data and Select Data for Models"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"59d28615-7370-4b5f-8d4f-092084ac79cb"}}},{"cell_type":"code","source":["# READ JOINED DATA\n\n# NEW LINK FOR DATA INCLUDING TIME OF DAY\n# df_airlines = spark.read.parquet(f\"{blob_url}/mlpipeline_set_time_of_day_zl_0403\").cache()\n\n# READ DATA INCLUDING AIRPORT RANK.\n# df_airlines = spark.read.parquet(f\"{blob_url}/df_airlines_rank\").cache()\nairlines = spark.read.parquet(f\"{blob_url}/df_airlines_rank_graphs\").cache()\n\n# CONTINUE WITH A PORTION OF DATA FOR TESTING\n# proportion = 0.05   # 0.025\n# (airlines, airline_rest) = airlines_total.randomSplit([proportion, 1- proportion], seed=123)\n\n#CONTINUE WITH ALL DATA\n# airlines.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"934d95ac-dc41-4d96-9351-dc8669199992"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Select only the columns needed\nairlines = airlines.select('YEAR','QUARTER','MONTH','DAY_OF_MONTH','DAY_OF_WEEK',\n                                         'OP_CARRIER_AIRLINE_ID', 'ORIGIN_AIRPORT_ID','DEST_AIRPORT_ID',\n                                         'CRS_DEP_TIME','DEP_DELAY','DEP_DELAY_NEW','DEP_DEL15','DEP_DELAY_GROUP','DISTANCE','DISTANCE_GROUP',\n                                         'wind_speed_mps_orig','ceiling_ht_dim_orig','visibility_meters_orig','temp_cels_orig','dew_pt_orig','atmos_press_orig','precip_milimeters_orig',\n                                         'wind_speed_mps_dest','ceiling_ht_dim_dest','visibility_meters_dest','temp_cels_dest','dew_pt_dest','atmos_press_dest','precip_milimeters_dest',\n                                         'rolling_ninety_day_average','Air_Page_Rank_traffic','Delay_block','OD_delay_pair',\n                                         'SEASON','WKDAY','DEPARTURE_Hour_CRS', 'time_of_day_int', 'Cnn_Ranking_val','Delay_Ranking_val',\n                                         'Coalesced_PgRank_orig', 'Coalesced_PgRank_dest', 'Conn_Ranking_orig', 'Conn_Ranking_dest').cache()\n\n# OUTCOME VARIABLES: DEP_TIME  DEP_DEL15\nairlines = airlines.dropna()\n\n# CHECK FOR BALANCE - LARGE DATASET\nairlines.groupBy(\"DEP_DEL15\").agg((count(col(\"DISTANCE\"))).alias(\"COUNT_DISTANCE\")).display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66ffeee8-8755-4fe3-b63e-7dcf755cb347"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 4. Using Delta Lakes - Skip if Using Airlines"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1bee191a-671d-42af-9cd9-f9659ba38a38"}}},{"cell_type":"code","source":["# FULL DATA = airline_joins_sel\n\n# Configure Path\n#FIRST ITERATION\n# DELTALAKE_GOLD_PATH = f\"{blob_url}/airline_rank_CEM_CAR20.delta\"\n# WHEN COYING BY OTHERS\nDELTALAKE_GOLD_PATH = f\"{blob_url}/airline_rank_CEM_CAR21.delta\"\n\n# Remove table if it exists\ndbutils.fs.rm(DELTALAKE_GOLD_PATH, recurse=True)\n\n# Save table as Delta Lake\nairlines.write.format(\"delta\").mode(\"overwrite\").save(DELTALAKE_GOLD_PATH)\n\n# Re-read as Delta Lake\nairlines = spark.read.format(\"delta\").load(DELTALAKE_GOLD_PATH)\n\n# CHECK FOR BALANCE - LARGE DATASET\nairlines.groupBy(\"DEP_DEL15\").agg((count(col(\"DISTANCE\"))).alias(\"COUNT_DISTANCE\")).display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bebb38ef-ce70-4148-877f-309a355f1caa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["airlines.groupBy(\"DEP_DEL15\", \"Cnn_Ranking_val\").agg((count(col(\"DISTANCE\"))).alias(\"COUNT_DISTANCE\")).display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"02481278-e5b7-40bb-ab6f-c44d833677a7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 5. Functions for Managing Imbalance Data based on DEP_DEL15"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97bd0f4b-4a29-4543-9cfa-7fe9d0febd11"}}},{"cell_type":"code","source":["def oversampling_Adj(data, column, val1, val2):\n\n  '''\n  Input: data = (dataframe with data), column = (column to check ratio for), val1 = majority value for column, val2 = minority value for column\n  Output: dataframe with balanced count for minority and majority count by oversampling minority count.\n  '''\n  \n  major_df = data.filter(col(column) == val1)\n  minor_df = data.filter(col(column) == val2)\n  n1 = minor_df.count()\n  n2 = major_df.count()\n  ratio = int(n2/n1)\n  \n  a = range(ratio+1)\n  \n  # duplicate the minority rows using explode and lit functions.\n  oversampled_df = minor_df.withColumn(\"dummy\", explode(array([lit(x) for x in a]))).drop('dummy')\n  n3 = oversampled_df.count()\n  if n3>n2: oversampled_df = oversampled_df.sample(False, n2/n3, 123)\n  \n  # combine both oversampled minority data and majority data \n  combined_df = major_df.unionAll(oversampled_df)\n  return combined_df, ratio"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13a9faa4-70a2-4845-ae55-beef63b8ca61"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def undersampling_Adj(data, column, val1, val2):\n\n  '''\n  Input: data = (dataframe with data), column = (column to check ratio for), val1 = majority value for column, val2 = minority value for column\n  Output: dataframe with balanced count for minority and majority count by undersampling majority count.\n  '''\n  \n  major_df = data.filter(col(column) == val1)\n  minor_df = data.filter(col(column) == val2)\n  n1 = major_df.count()\n  n2 = minor_df.count()\n  ratio = n2/n1\n    \n  sampled_majority_df = major_df.sample(False, ratio, 123)\n  combined_df = sampled_majority_df.unionAll(minor_df)\n\n  return combined_df, ratio"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08540ccb-756f-4dac-9031-09bef02c27d4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def balancesampling_Adj(data, column, val1, val2, adj):\n\n  '''\n  Input: data = (dataframe with data), column = (column to check ratio for), val1 = majority value for column, val2 = minority value for column, adj = factor to adjust balance\n  Output: dataframe with balanced count for minority and majority count by balancing minority and majority count.\n  '''\n  \n  major_df = data.filter(col(column) == val1)\n  minor_df = data.filter(col(column) == val2)\n  n1 = major_df.count()\n  n2 = minor_df.count()\n  t2 = (n1 + n2)/2 \n  ratio = int((n1/n2)/adj)\n  \n  a = range(ratio)\n  \n  # duplicate the minority rows using explode and lit functions.\n  oversampled_df = minor_df.withColumn(\"dummy\", explode(array([lit(x) for x in a]))).drop('dummy')\n  n3 = oversampled_df.count()\n  oversampled_df = oversampled_df.sample(False, t2/n3, 123)\n    \n  # downsampling oversampled minority and majority data to achieve balanced data\n  major_df = major_df.sample(False, t2/n1, 123)\n\n  # combine both adjusted oversampled minority data and majority data \n  combined_df = major_df.unionAll(oversampled_df)\n  return combined_df, [ratio, t2/n1]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"838e0652-0c33-4466-a2eb-8cee77617fcb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def createSplits(data, year, last_year, delta, flag):\n  # Set Dictionary with Data Splits\n\n  '''\n  Input:\n    data: data for split\n    year: first year to be used for validation\n    last_year: last year to be considered for validation\n    delta: size of range for training data\n    flag: True if delta increases by one (for expanding window)\n  Output: Dictionary with splits for test and train.\n  '''\n  d = {}\n  i = 1\n  while year <= last_year:\n    dfname = \"df\"+str(i)\n    print(\"Creating split \", i,\" for \", dfname, \"- Val Year: \", year, \" Train year: \", year-delta, \"-\", year-1)\n    d[dfname] = data.filter( (data.YEAR <= year) & (data.YEAR >= year-delta))\\\n                    .withColumn('cv', when(data.YEAR <= year-1, 'train')\n                    .otherwise('test'))\n    i += 1\n    year += 1\n    if flag: delta +=1\n  \n  return d"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b832934e-bfba-42fd-955e-3ee97b98e9f1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 6. Set Data for ML Models and Create Partitions for Grid Search"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8b8452e6-f8b1-43ab-8bcb-7d8c8a7b2fe5"}}},{"cell_type":"markdown","source":["##### - Select Variables and Manage Unbalance Data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5257d927-edb8-410f-95e2-0a78220aec57"}}},{"cell_type":"code","source":["myY = \"DEP_DEL15\"\n\n# categoricals = [ 'QUARTER', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_CARRIER_AIRLINE_ID', 'ORIGIN_AIRPORT_ID', 'DEST_AIRPORT_ID', \n#                 'SEASON', 'WKDAY', 'DEPARTURE_Hour_CRS', 'time_of_day_int']\n\n# numerics = [ 'DISTANCE', 'wind_speed_mps_orig', 'ceiling_ht_dim_orig', 'visibility_meters_orig', 'temp_cels_orig', 'dew_pt_orig', 'atmos_press_orig', 'precip_milimeters_orig', 'wind_speed_mps_dest', 'ceiling_ht_dim_dest', 'visibility_meters_dest', 'temp_cels_dest', 'dew_pt_dest', 'atmos_press_dest', 'precip_milimeters_dest', 'rolling_ninety_day_average', 'Air_Page_Rank_traffic','OD_delay_pair', 'Coalesced_PgRank_orig', 'Coalesced_PgRank_dest', 'Conn_Ranking_orig', 'Conn_Ranking_dest']\n\n# NI = ['YEAR','Cnn_Ranking_val','Delay_Ranking_val' ]\n\ncategoricals = [ 'MONTH',  'OP_CARRIER_AIRLINE_ID', 'ORIGIN_AIRPORT_ID', 'DEST_AIRPORT_ID', \n                'SEASON',  'DEPARTURE_Hour_CRS', 'time_of_day_int']\n\nnumerics = [ 'wind_speed_mps_orig', 'ceiling_ht_dim_orig', 'visibility_meters_orig', 'temp_cels_orig', 'dew_pt_orig', 'precip_milimeters_orig', 'wind_speed_mps_dest', 'temp_cels_dest',  'precip_milimeters_dest', 'rolling_ninety_day_average', 'OD_delay_pair', 'Coalesced_PgRank_orig']\n\nNI = ['YEAR', 'Cnn_Ranking_val']\n\n\n# 'CRS_DEP_TIME', 'DEP_DELAY', 'DEP_DELAY_NEW', 'DEP_DEL15', 'DEP_DELAY_GROUP'\n\nmyX = categoricals + numerics\n\n# SELECT THE COLUMNS WITH THE VARIABLES\nairlines2 = airlines.select(myX + [myY, \"DEP_DELAY_NEW\", \"DEP_DELAY\"] + NI)\n\n# UNCOMMENT LINE FOR DESIRED APPROACH TO BALANCE DATA\n# airlines2, rs = oversampling_Adj(airlines2, \"DEP_DEL15\", 0, 1)\n# airlines2, rs = undersampling_Adj(airlines2, \"DEP_DEL15\", 0, 1)\n# airlines2, rs = balancesampling_Adj(airlines2, \"DEP_DEL15\", 0, 1, 1)\n\n#CREATE A COPY OF myY with name label to be used in the Grid Search \nairlines2 = airlines2.withColumn(\"label\", airlines2[myY])\n\nairlines2.groupBy(\"label\").agg((count(col(myY))).alias(\"COUNT_DISTANCE\")).display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"07755ec0-76f3-4587-a625-7534a99f1588"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["test_unbalanced = airlines.select(myX + [myY, \"DEP_DELAY_NEW\", \"DEP_DELAY\"] + NI).filter(airlines2.YEAR > 2018).cache()\ntest_unbalanced = test_unbalanced.withColumn(\"label\", test_unbalanced[myY]).cache()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ecf1b596-ae08-4d3f-813e-ea6da7d43a65"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### - Include a Weight Column for Weighted Models"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39289f4a-aa5c-43a4-808b-06fee953226e"}}},{"cell_type":"code","source":["# INCLUDE WEIGHTS FOR IMPLEMENTATION OF WEIGHTED MODELS\nmajority = airlines2.filter(col(myY) == 0).count()\nminority = airlines2.filter(col(myY) == 1).count()\ncount_total = majority + minority\n\n# Weights\nc, F = 2, 1\nweight_minority = count_total / (c * minority * F)\nweight_majority = count_total / (c * (count_total - minority))\n\n# Weights\nc, F = 2, 0.98\nweight1_minority = count_total / (c * minority * F)\nweight1_majority = count_total / (c * (count_total - minority))\n\n# Weights\nc,  F = 2, 0.95\nweight2_minority = count_total / (c * minority * F)\nweight2_majority = count_total / (c * (count_total - minority))\n\nairlines2 = airlines2.withColumn(\"weight\", when(col(myY) ==1, weight_minority).otherwise(weight_majority))\nairlines2 = airlines2.withColumn(\"weight1\", when(col(myY) ==1, weight1_minority).otherwise(weight1_majority))\nairlines2 = airlines2.withColumn(\"weight2\", when(col(myY) ==1, weight2_minority).otherwise(weight2_majority))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a404ab85-7093-4ca6-835b-014bac4a3818"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### - Split Data for Training, Validation and Testing.  Create Folds for Grid Search"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e0e68c5-e73e-49c1-b0f5-e315553413b2"}}},{"cell_type":"code","source":["# SPLIT DATA FOR TRAINING AND VALIDATION\nyear_train_val = 2018\ntrain_val = airlines2.filter(airlines2.YEAR <= year_train_val).cache()\ntest = airlines2.filter(airlines2.YEAR > year_train_val).cache()\n\ntrainCase = train_val\n\n# CREATE SPLITS FOR CROSS VALIDATION - FIRST VALIDATION ON 2016, AND LAST VALIDATION ON 2018 - EXPANDING WINDOW STARTING WITH STEP ONE.\nd = createSplits(train_val, 2016, 2018, 1, True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c4e2d87-3c19-4712-b8ce-ac9aea326305"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### - Define Indexers, Ohes, Imputers, Scalers"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"46a85e74-fbb7-4eb1-a072-872595c709f5"}}},{"cell_type":"code","source":["## Current possible ways to handle categoricals in string indexer is 'error', 'keep', and 'skip'\nindexers = map(lambda c: StringIndexer(inputCol=c, outputCol=c+\"_idx\", handleInvalid = 'keep'), categoricals)\nohes = map(lambda c: OneHotEncoder(inputCol=c + \"_idx\", outputCol=c+\"_class\", dropLast=True),categoricals)\nimputers = Imputer(inputCols = numerics, outputCols = numerics)\n\n# Establish features columns\nfeatureCols = list(map(lambda c: c+\"_class\", categoricals)) + numerics\n\nmodel_matrix_stages = list(indexers) + list(ohes) + [imputers] + \\\n                     [VectorAssembler(inputCols=featureCols, outputCol=\"features\")]\n\n# Apply StandardScaler to create scaledFeatures\nscaler = StandardScaler(inputCol=\"features\",\n                        outputCol=\"scaledFeatures\",\n                        withStd=True,\n                        withMean=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"515fa8a5-cc9b-4bad-9a42-68172be05084"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 7. Grid Search Pipeline\n###### Models Available: Random Forest (RF), Logistic Regression (LogR), Gradient Boosted Tree (GBT), and Linear Vector Support Classifier (LVSC)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8f8b8262-d0e3-4b8e-a0ec-af37ad41beec"}}},{"cell_type":"code","source":["from pyspark.ml.classification import MultilayerPerceptronClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\ndef create_model(d_seg, model_matrix_stages, scaler, ModelType):\n  '''\n  Input: \n    - d_seg: data folds for Grid Search\n    - model_matrix_stages (indexers, ohes, imputers, vector assembler)\n    - scaler: StandardScaler (no PCA included in pipeline)\n    - ModelType: Models Available: Random Forest (RF), Logistic Regression (LogR), Gradient Boosted Tree (GBT), and Linear Vector Support Classifier (LVSC)\n  Output:\n    - GridSearch Pipeline model fitted to data folds (d_seg)\n  '''\n\n  if ModelType == \"RF\":\n    # Define a Random Forest model - not using PCA\n    md = RandomForestClassifier(featuresCol = 'scaledFeatures', labelCol = 'label',\n                                featureSubsetStrategy='auto', \n                                impurity='gini',\n                                seed=123)\n\n    # Set the Grid Search set of parameters\n    grid = ParamGridBuilder()\\\n                .addGrid(md.maxDepth, [5, 8, 10, 12, 14])\\\n                .addGrid(md.numTrees, [80, 100, 110, 150])\\\n                .build()\n    \n  elif ModelType == \"LogR\":\n    md = LogisticRegression(maxIter=20, featuresCol = \"scaledFeatures\", weightCol=\"weight\")\n    \n      # Set the Grid Search set of parameters\n    grid = ParamGridBuilder()\\\n                .addGrid(md.regParam, [0.1, 0.05, 0.01])\\\n                .addGrid(md.elasticNetParam, [0, 0.5, 1])\\\n                .build()\n    \n  elif ModelType == \"GBT\":\n    \n    # Define a GBT model.\n    md = GBTClassifier(featuresCol=\"scaledFeatures\",      # alternative to include scaled features: \"scaledFeatures\"\n                        labelCol=\"label\",\n                        lossType = \"logistic\",\n                        maxBins = 350,   #Replaced 52\n                        weightCol= 'weight')\n\n    # Set the Grid Search set of parameters\n    grid = ParamGridBuilder()\\\n                .addGrid(md.maxDepth, [5, 8, 10])\\\n                .addGrid(md.maxIter, [10, 15, 20])\\\n                .build()\n    \n  elif ModelType == \"LSVC\":\n    # Define a GBT model.\n    md = LinearSVC(featuresCol=\"scaledFeatures\",      # alternative to include scaled features: \"scaledFeatures\"\n                   labelCol=\"label\",\n                   maxIter=10,\n                   weightCol= 'weight'\n                  )\n    grid = ParamGridBuilder()\\\n                  .addGrid(md.regParam, [0.1, 0.05, 0.01])\\\n                .build()\n \n  elif ModelType == \"MPC\":\n    # Define a MPC model.\n    # specify layers for the neural network:\n    # input layer of size N (features),\n    # and output of size 2 (classes)\n    \n    layers = [[735, 32, 64, 32, 2], [735, 8, 16, 8, 2], [735, 16, 32, 16, 2]]\n\n#     layers = [[735, 32, 64, 32, 2], [735, 16, 32, 16, 2]]\n    \n    md = MultilayerPerceptronClassifier(maxIter=100, blockSize=128, seed=1234)\n\n    # Set the Grid Search set of parameters\n    grid = ParamGridBuilder()\\\n                .addGrid(md.layers, layers)\\\n                .build()\n\n  # Build our ML pipeline\n  \n  pipeline = Pipeline(stages=model_matrix_stages+[scaler]+[md])\n\n\n  evaluator = BinaryClassificationEvaluator()\n\n  # Execute CrossValidator for model tuning\n  crossval = CustomCrossValidator(estimator=pipeline,\n                                  estimatorParamMaps=grid,\n                                  evaluator=evaluator,\n                                  splitWord = ('train', 'test'),\n                                  cvCol = 'cv',\n                                  parallelism=4)\n\n  # Train the tuned model and establish our best model\n  Model_seg = crossval.fit(d_seg)\n  \n  return Model_seg"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"359691e4-29c8-4c51-b708-013bf002b090"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### a. Grid Search for Random Forest (Batch Process)\n###### Run Grid Search Pipeline, Print Metrics, Save Model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e29ebedd-dbf0-4dd4-9796-5bdc2696822e"}}},{"cell_type":"code","source":["# Testing MultilayerPerceptronClassifier\n# Type of Model: \"RF\" = Random Forest, \"LogR\" = Logistic Regression, \"GBT\" = Gradient Boosted Trees, \"LSVC\" = Linear Support Vector Classifier\nmodelName = \"RF\"\n\n# Create and fit pipeline to data (d)\nrf_pipeline = create_model(d, model_matrix_stages, scaler, modelName)\n\n# Get best model and print performance metrics\nrf_model = rf_pipeline.bestModel\npred = rf_model.transform(test).select(\"DEP_DEL15\", \"prediction\")\nmetricsT = MulticlassMetrics(pred.rdd.map(lambda x: (x[1], x[0])))\nm2 = metricsdf2(metricsT)\ndfM_rf = pd.DataFrame({modelName: list(m2.values())}, index = list(m2.keys()))\ndfM_rf"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"acb708a1-1d4c-43ad-b473-3214fb3074a4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["RF: Best Model:\n{Param(parent='RandomForestClassifier_6fe29fa7db1b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 14, Param(parent='RandomForestClassifier_6fe29fa7db1b', name='numTrees', doc='Number of trees to train (>= 1).'): 250} Detailed Score [0.7124449378591117, 0.711729788988346, 0.7133298648993877] Avg Score 0.7125015305822817\n\nUsing 19 variables:\nBest Model:  {Param(parent='RandomForestClassifier_030856b0d53a', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 14, Param(parent='RandomForestClassifier_030856b0d53a', name='numTrees', doc='Number of trees to train (>= 1).'): 110} Detailed Score [0.7117320780331156, 0.7112025132790081, 0.7107323084360173] Avg Score 0.711222299916047"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"71a21fc4-b998-4461-b5ff-2f3b65d9e1af"}}},{"cell_type":"code","source":["# Erase MODEL\nmodel_path = f\"{blob_url}/models/rf_model\"\ndbutils.fs.rm(model_path, True)\n\n# Save the MODEL\nrf_model.save(model_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0fb87b96-18a9-4af4-8bc7-6018a44066ba"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### b. Grid Search for Logistic Regression (Batch Process)\n###### Run Grid Search Pipeline, Print Metrics, Save Model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"176a21f9-42b4-44f0-aeb1-c90ea424f3f5"}}},{"cell_type":"code","source":["# Type of Model: \"RF\" = Random Forest, \"LogR\" = Logistic Regression, \"GBT\" = Gradient Boosted Trees, \"LSVC\" = Linear Support Vector Classifier\nmodelName = \"LogR\"\nlogr_pipeline = create_model(d, model_matrix_stages, scaler, modelName)\n\nlogr_model = logr_pipeline.bestModel\npred = logr_model.transform(test).select(\"DEP_DEL15\", \"prediction\")\nmetricsT = MulticlassMetrics(pred.rdd.map(lambda x: (x[1], x[0])))\nm2 = metricsdf2(metricsT)\ndfM_lr = pd.DataFrame({modelName: list(m2.values())}, index = list(m2.keys()))\ndfM_lr"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dadaafb4-f276-4ada-9140-e8ff8f12df86"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["LogR: Best Model:  {Param(parent='LogisticRegression_b84ba01371d9', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='LogisticRegression_b84ba01371d9', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5} Detailed Score [0.6897965704488692, 0.6832426835147819, 0.6859631304773205] Avg Score 0.6863341281469906\nOut[67]:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae23ee8a-f614-465d-ac9c-d4a4e5949a7b"}}},{"cell_type":"code","source":["# Erase MODEL\nmodel_path = f\"{blob_url}/models/logr_model\"\ndbutils.fs.rm(model_path, True)\n\n# Save the MODEL\nlogr_model.save(model_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2acddf1-8d2f-4b1b-b547-991c3aef5378"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### c. Grid Search for GBT - Gradient Boosted Tree\n###### Run Grid Search Pipeline, Print Metrics, Save Model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"937997f3-1bb3-4592-8a40-155663887c23"}}},{"cell_type":"code","source":["# Type of Model: \"RF\" = Random Forest, \"LogR\" = Logistic Regression, \"GBT\" = Gradient Boosted Trees, \"LSVC\" = Linear Support Vector Classifier\nmodelName = \"GBT\"\ngbt_pipeline = create_model(d, model_matrix_stages, scaler, modelName)\n\ngbt_model = gbt_pipeline.bestModel\npredgbt = gbt_model.transform(test).select(\"DEP_DEL15\", \"prediction\")\nmetricsgbt = MulticlassMetrics(predgbt.rdd.map(lambda x: (x[1], x[0])))\nmgbt = metricsdf2(metricsgbt)\ndfgbt = pd.DataFrame({modelName: list(mgbt.values())}, index = list(mgbt.keys()))\ndfgbt"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ed397f1-e751-4faa-9a0e-41e5bdecf665"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["GBT: Best Model:  {Param(parent='GBTClassifier_f85db42a2d71', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='GBTClassifier_f85db42a2d71', name='maxIter', doc='max number of iterations (>= 0).'): 20} Detailed Score [0.7095841683238695, 0.7070802054050617, 0.7107503772097722] Avg Score 0.7091382503129011"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5afacd7c-4c63-44c3-8c11-de4e2ceb6862"}}},{"cell_type":"code","source":["# Erase MODEL\nmodel_path = f\"{blob_url}/models/gbt_model\"\ndbutils.fs.rm(model_path, True)\n\n# Save the MODEL\ngbt_model.save(model_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5fd8ba76-6425-4683-89b0-322bd4f5d08c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### d. Grid Search for LSVC Batch Process\n###### Run Grid Search Pipeline, Print Metrics, Save Model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f05ec058-1815-4a20-8449-da30fa32047a"}}},{"cell_type":"code","source":["# Type of Model: \"RF\" = Random Forest, \"LogR\" = Logistic Regression, \"GBT\" = Gradient Boosted Trees, \"LSVC\" = Linear Support Vector Classifier\nmodelName = \"LSVC\"\nlsvc_pipeline = create_model(d, model_matrix_stages, scaler, modelName)\n\nlsvc_model = lsvc_pipeline.bestModel\npredlsvc = lsvc_model.transform(test).select(\"DEP_DEL15\", \"prediction\")\nmetricslsvc = MulticlassMetrics(predlsvc.rdd.map(lambda x: (x[1], x[0])))\nmlsvc = metricsdf2(metricslsvc)\ndflsvc = pd.DataFrame({modelName: list(mlsvc.values())}, index = list(mlsvc.keys()))\ndflsvc"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e5d2c60-56d5-4092-a763-c75b10e81094"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["LSVC: Best Model:  {Param(parent='LinearSVC_63470e83e35e', name='regParam', doc='regularization parameter (>= 0).'): 0.01} Detailed Score [0.685944064672475, 0.6807187279762132, 0.6823800942462118] Avg Score 0.6830142956316334"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e9f061fb-6ee1-49d9-921b-bc428df2579c"}}},{"cell_type":"code","source":["# Erase MODEL\nmodel_path = f\"{blob_url}/models/lsvc_model\"\ndbutils.fs.rm(model_path, True)\n\n# Save the MODEL\nlsvc_model.save(model_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"051a6147-f558-47f1-8301-6e307c2cd60a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### e. Summary Commands to Load Models"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ad52262-7738-4509-9076-3c5f5848b4a2"}}},{"cell_type":"code","source":["# Loading a Radom Forest Saved Model\nmodel_path = f\"{blob_url}/models/rf_model\"\nrf_saved_model = rf_model.load(model_path)\n\n# Loading a Log Regression Saved Model\nmodel_path = f\"{blob_url}/models/logr_model\"\nlogr_saved_model = logr_model.load(model_path)\n\n# Loading a Log Regression Saved Model\nmodel_path = f\"{blob_url}/models/gbt_model\"\ngbt_saved_model = gbt_model.load(model_path)\n\n# Loading a Log Regression Saved Model\nmodel_path = f\"{blob_url}/models/lsvc_model\"\nlsvc_saved_model = lsvc_model.load(model_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88e084d0-0a5a-4b39-8581-2a2b1fe7cfc7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 8. Generate Grid Searched Models in Batch (RF, LogR, GBT, LSVC)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2111b8ed-753d-43f8-a13b-afa7297a9131"}}},{"cell_type":"code","source":["modelName = [\"RF\", \"LogR\", \"GBT\", \"LSVC\"]\nmodelList = []\nmetricList = []\ni = 0\nfor modelN in modelName:\n  print(\"Working on Model: \", modelN)\n  model = create_model(d, model_matrix_stages, scaler, modelN)\n  bestmodel = model.bestModel\n  \n  pred = bestmodel.transform(test).select(\"DEP_DEL15\", \"prediction\")\n  metricsT = MulticlassMetrics(pred.rdd.map(lambda x: (x[1], x[0])))\n  m2 = metricsdf2(metricsT)\n  dfM = pd.DataFrame({modelN: list(m2.values())}, index = list(m2.keys()))\n  if i == 0:\n    dfM_consolidated = dfM\n    i += 1\n  else:\n    dfM_consolidated = pd.concat([dfM_consolidated,dfM],axis=1)\n  \n#   print(dfM)\n  modelList.append(model)\n  metricList.append(dfM)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c9f129ad-5855-4f6d-bb8c-d5944a1c7461"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["dfM_consolidated"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"34a61e90-3d5b-4d6d-be60-fcf6a6790e46"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 9. Fit and Test Best Random Forest Model - No PCA"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f10b0e76-8c0c-4b91-881b-fa52cb7db1b8"}}},{"cell_type":"markdown","source":["##### a. Random Forest Best Configuration"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9faca854-3a28-46db-83ab-468d1396ebb2"}}},{"cell_type":"code","source":["def rf_pipeline_best(data, maxDepth, numTrees, model_matrix_stages, scaler):\n  \n  # Define a Random Forest model - not using PCA\n  rf = RandomForestClassifier(featuresCol = 'scaledFeatures', labelCol = 'label',\n                              featureSubsetStrategy='auto', \n                              impurity='gini',\n                              maxDepth = maxDepth,\n                              numTrees = numTrees,\n                              seed=123)\n\n\n  pipeline = Pipeline(stages=model_matrix_stages+[scaler]+[rf])\n\n\n  # Train the tuned model and establish our best model\n  pipeline_rf = pipeline.fit(data)\n  \n  return pipeline_rf"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5230116b-db7e-4896-8e57-98eda09b6df8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# DO NOT RUN THIS - MOVE TO NEXT CELL\nyear_train_val = 2018\nlower_end = 2015\n# train_val = airlines2.filter(airlines2.YEAR <= year_train_val).cache()\n# test = airlines2.filter(airlines2.YEAR > year_train_val).cache()\n\ntrainCase = airlines2.filter( (airlines2.YEAR <= year_train_val) & (airlines2.YEAR >= lower_end)  ).cache()\nmaxDepth = 14\nnumTrees = 250\n\nrf_pipeline_test = rf_pipeline_best(trainCase, maxDepth, numTrees, model_matrix_stages, scaler)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d262ab7d-0ae0-46d4-8438-c4f6b50687fd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# train_val.unpersist()\n# airlines.unpersist()\n# airlines2.unpersist()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"76adf46f-ad65-46d4-a37a-235bf1f6dae5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# RUN THIS FOR RANDOM FOREST\nrf = RandomForestClassifier(featuresCol = 'scaledFeatures', labelCol = 'label',\n                            featureSubsetStrategy='auto', \n                            impurity='gini',\n                            maxDepth = 14,\n                            numTrees = 110,\n                            seed=123)\n\npipelineRF = Pipeline(stages=model_matrix_stages+[scaler]+[rf])\n\nmodel_RF = pipelineRF.fit(train_val)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6521328a-ba17-413f-abbd-b1536c7b9eb0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# GET PREDICTIONS -> DEP_DEL15, P0, P1, LABEL, PREDICTION\ntvprd = score(model_RF, train_val)\ntestprd = score(model_RF, test_unbalanced)\n\nrfM = metricsdf([tvprd, testprd], [\"RF_train\", \"RF_test\"])\nrfM"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b27d2a8e-92cf-4cda-b764-7e95ad810d6a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[129]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[129]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RF_train</th>\n      <th>RF_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.657424</td>\n      <td>0.648145</td>\n    </tr>\n    <tr>\n      <th>Precision</th>\n      <td>0.296531</td>\n      <td>0.297438</td>\n    </tr>\n    <tr>\n      <th>Recall</th>\n      <td>0.654366</td>\n      <td>0.648226</td>\n    </tr>\n    <tr>\n      <th>Specificity</th>\n      <td>0.658097</td>\n      <td>0.648126</td>\n    </tr>\n    <tr>\n      <th>F1_Score</th>\n      <td>0.408119</td>\n      <td>0.407771</td>\n    </tr>\n    <tr>\n      <th>F05_Score</th>\n      <td>0.332944</td>\n      <td>0.333537</td>\n    </tr>\n    <tr>\n      <th>F2_Score</th>\n      <td>0.527142</td>\n      <td>0.524509</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RF_train</th>\n      <th>RF_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.657424</td>\n      <td>0.648145</td>\n    </tr>\n    <tr>\n      <th>Precision</th>\n      <td>0.296531</td>\n      <td>0.297438</td>\n    </tr>\n    <tr>\n      <th>Recall</th>\n      <td>0.654366</td>\n      <td>0.648226</td>\n    </tr>\n    <tr>\n      <th>Specificity</th>\n      <td>0.658097</td>\n      <td>0.648126</td>\n    </tr>\n    <tr>\n      <th>F1_Score</th>\n      <td>0.408119</td>\n      <td>0.407771</td>\n    </tr>\n    <tr>\n      <th>F05_Score</th>\n      <td>0.332944</td>\n      <td>0.333537</td>\n    </tr>\n    <tr>\n      <th>F2_Score</th>\n      <td>0.527142</td>\n      <td>0.524509</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Random Forest Confusion Matrix\ntestprd.groupBy(\"DEP_DEL15\", \"prediction\").count().display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"399d5d0e-74be-44cd-afd3-3d71799a66d0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["metricsRF = MulticlassMetrics(testprd.rdd.map(lambda x: (x[4], x[3])))\nrfM2 = metricsdf2(metricsRF)\ndfMrf = pd.DataFrame({\"RF\": list(rfM2.values())}, index = list(rfM2.keys()))\ndfMrf"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"087254b2-e7c5-4c24-8293-07a7812c225a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# LOOK TO TRY DIFFERENT CUTS FOR TRAINING DATA\nyear_train_val = 2018\nmaxDepth = 10\nnumTrees = 110\n\nresult_list = []\nname_list = []\nfor lower_end in [2015, 2016, 2017, 2018]:\n  \n  print(\"Lower Year: \",lower_end) \n  trainCase = airlines2.filter( (airlines2.YEAR <= year_train_val) & (airlines2.YEAR >= lower_end)  ).cache()\n  rf_pipeline_test = rf_pipeline_best(trainCase, maxDepth, numTrees, model_matrix_stages, scaler)\n\n  testprd = score(rf_pipeline_test, test)\n  result_list.append(testprd)\n  name = \"RF-\"+str(lower_end)+\"-\"+str(year_train_val)\n  name_list.append(name)\n  \nrfM = metricsdf(result_list, name_list) \nrfM"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b91892e8-eef5-4659-8130-991e099af1d0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### b. Best GBT"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1874174d-3c4e-4c13-8bb4-c6779c9b6c96"}}},{"cell_type":"code","source":["gbt = GBTClassifier(featuresCol=\"scaledFeatures\",      # alternative to include scaled features: \"scaledFeatures\"\n                    labelCol=\"label\",\n                    lossType = \"logistic\",\n                    maxDepth = 5,\n                    maxIter = 20,\n                    maxBins = 350,   #Replaced 52\n                    weightCol= 'weight')\n\npipelineGBT = Pipeline(stages=model_matrix_stages+[scaler]+[gbt])\n\nmodel_GBT = pipelineGBT.fit(trainCase)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c22c3f27-bc95-43ed-a0fa-c1f621796fad"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# GET PREDICTIONS -> DEP_DEL15, P0, P1, LABEL, PREDICTION\ntvpgbt = score(model_GBT, trainCase)\ntestpgbt = score(model_GBT, test_unbalanced)\n\ngbtM = metricsdf([tvpgbt, testpgbt], [\"GBT_train\", \"GBT_test\"])\ngbtM"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ef7b8bb-9758-4ba3-ada9-2a50684bdcbf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### c. LSVC"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ad43db8-59f2-4078-9110-8f28d323d746"}}},{"cell_type":"code","source":["lsvc = LinearSVC(featuresCol=\"scaledFeatures\",      # alternative to include scaled features: \"scaledFeatures\"\n               labelCol=\"label\",\n               maxIter=10,\n               weightCol= 'weight',\n               regParam = 0.01\n              )\n\npipelineLSVC = Pipeline(stages=model_matrix_stages+[scaler]+[lsvc])\n\nmodel_LSVC = pipelineLSVC.fit(trainCase)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"58908939-62ca-4e00-87c9-72fc6a8603fb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# GET PREDICTIONS -> DEP_DEL15, P0, P1, LABEL, PREDICTION\n\nPlsvc = model_LSVC.transform(test_unbalanced).select(\"DEP_DEL15\", \"prediction\")\nMlsvc = MulticlassMetrics(Plsvc.rdd.map(lambda x: (x[1], x[0])))\nsumlsvc = metricsdf2(Mlsvc)\nlsvc = pd.DataFrame({\"LSVC\": list(sumlsvc.values())}, index = list(sumlsvc.keys()))\nlsvc"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bc9b4f0a-c50c-408f-a28f-972c03fd6e39"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["Plsvc = model_LSVC.transform(trainCase).select(\"DEP_DEL15\", \"prediction\")\nMlsvc = MulticlassMetrics(Plsvc.rdd.map(lambda x: (x[1], x[0])))\nsumlsvc = metricsdf2(Mlsvc)\nlsvc = pd.DataFrame({\"LSVC\": list(sumlsvc.values())}, index = list(sumlsvc.keys()))\nlsvc"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64b20f92-cf96-46c6-b18b-e9a7ead5f2f3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### d. Logistic Regression"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aaa4f452-38bd-43e3-a3b6-52feedbf6d5e"}}},{"cell_type":"code","source":["lr = LogisticRegression(maxIter=20, featuresCol = \"scaledFeatures\", weightCol=\"weight\", regParam=0.01, elasticNetParam=0.5)\n\npipelineLR = Pipeline(stages=model_matrix_stages+[scaler]+[lr])\n\nmodel_LR = pipelineLR.fit(trainCase)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69604e55-26bf-491b-95b6-7da6712a0af0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# GET PREDICTIONS -> DEP_DEL15, P0, P1, LABEL, PREDICTION\ntvpLR = score(model_LR, trainCase)\ntestpLR = score(model_LR, test_unbalanced)\n\nlrM = metricsdf([tvpLR, testpLR], [\"LR_train\", \"LR_test\"])\nlrM"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6fb07e50-cd75-4184-b511-d80ab1080fd7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#dataframe.unpersist()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9556c88e-ad79-4171-a618-7c2d3eb2f528"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 10. Feature Importance - Random Forest Model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dfc3d3fe-e52c-4ba7-809d-7bdd90b83cbb"}}},{"cell_type":"code","source":["# year_train_val = 2018\n# lower_end = 2017\n# trainCase = airlines2.filter( (airlines2.YEAR <= year_train_val) & (airlines2.YEAR >= lower_end)  ).cache()\n# datamodel = rf_pipeline_test.transform(train_val)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22c58430-6ae0-41b7-bd20-baeb6e2e5a2d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def featureList2(model, datamodel, data, categoricals):\n  features = model.stages[-3].getInputCols()\n  sizelist = []\n  setcat = set(categoricals)\n  featurelist = []\n  for f in features:\n    fset = f[:len(f)-6]\n    if fset in setcat:\n      n = len(np.array(data.select(fset).distinct().collect()))\n      sizelist.append(n)\n      featurelist = featurelist + [fset]*n\n    else:\n      featurelist = featurelist + [f]\n      sizelist.append(1)\n  \n  return featurelist, sizelist"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0804e35b-7c55-4ee9-a316-38e2a4810494"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def featureList(model, datamodel, categoricals):\n  features = model.stages[-3].getInputCols()\n  sizelist = []\n  setcat = set(categoricals)\n  featurelist = []\n  for f in features:\n    fset = f[:len(f)-6]\n    if fset in setcat:\n      n = int(len(datamodel.select(f).take(1)[0][0].toArray()))\n      sizelist.append(n)\n      featurelist = featurelist + [fset]*n\n    else:\n      featurelist = featurelist + [f]\n      sizelist.append(1)\n  \n  return featurelist, sizelist"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"caa7bcdb-466c-404e-8a2b-1d881f1350a4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def get_feature_importance(model, traindata, categoricals):\n    \n  datamodel = model.transform(traindata)\n#   Use when using a dataset from Grid Search\n  featurelist, sizelist = featureList(model, datamodel, categoricals)\n\n  # Use when not using a dataset from Grid Search\n#   featurelist, sizelist = featureList2(model, datamodel, traindata, categoricals)\n\n  featureImp = model.stages[-1].featureImportances\n  Impfeatures = pd.DataFrame({\"atribute\":featurelist, \"importance\":featureImp})\n  \n  return Impfeatures"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef22d22b-fba4-4836-81bf-d07305ca73fa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# datamodel = rf_pipeline_test.transform(trainCase)\n# rf_model or rf_pipeline_test; trainCase, train_val\nimportantFeatures = get_feature_importance(model_RF, train_val, categoricals)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9574584a-6ce3-4072-9e36-0bc56e335a34"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["df1 = importantFeatures.groupby('atribute')['importance'].sum().sort_values(ascending=False).reset_index()\ndf1['CUMSUM_C'] = df1['importance'].cumsum()\ndf1"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"139cc112-bf74-441d-ae6d-b9ed98f77399"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### Test Model with Key Variables"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3c746603-9daf-42c3-9b15-bcfb81f69d05"}}},{"cell_type":"code","source":["myY2 = \"DEP_DEL15\"\n\ntake_out = ['WKDAY', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'DISTANCE', 'QUARTER', 'dew_pt_dest', 'atmos_press_dest', 'Conn_Ranking_dest',\n           'Delay_Ranking_val', 'Coalesced_PgRank_dest', 'Air_Page_Rank_traffic', 'visibility_meters_dest', 'Conn_Ranking_orig',\n           'atmos_press_orig', 'ceiling_ht_dim_dest']\n\ncategoricals2 = [ 'MONTH',  'OP_CARRIER_AIRLINE_ID', 'ORIGIN_AIRPORT_ID', 'DEST_AIRPORT_ID', \n                'SEASON',  'DEPARTURE_Hour_CRS', 'time_of_day_int']\n\nnumerics2 = [ 'wind_speed_mps_orig', 'ceiling_ht_dim_orig', 'visibility_meters_orig', 'temp_cels_orig', 'dew_pt_orig', 'precip_milimeters_orig', 'wind_speed_mps_dest', 'temp_cels_dest',  'precip_milimeters_dest', 'rolling_ninety_day_average', 'OD_delay_pair', 'Coalesced_PgRank_orig']\n\nNI2 = ['YEAR', 'Cnn_Ranking_val']\n# 'CRS_DEP_TIME', 'DEP_DELAY', 'DEP_DELAY_NEW', 'DEP_DEL15', 'DEP_DELAY_GROUP'\n\nmyX2 = categoricals2 + numerics2\n\n# SELECT THE COLUMNS WITH THE VARIABLES\nairlines3 = airlines.select(myX2 + [myY2, \"DEP_DELAY_NEW\", \"DEP_DELAY\"] + NI2)\n\n# UNCOMMENT LINE FOR DESIRED APPROACH TO BALANCE DATA\n# airlines2, rs = oversampling_Adj(airlines2, \"DEP_DEL15\", 0, 1)\nairlines3, rs = undersampling_Adj(airlines3, \"DEP_DEL15\", 0, 1)\n# airlines2, rs = balancesampling_Adj(airlines2, \"DEP_DEL15\", 0, 1, 1)\n\n#CREATE A COPY OF myY with name label to be used in the Grid Search \nairlines3 = airlines3.withColumn(\"label\", airlines3[myY])\n\nairlines3.groupBy(\"label\").agg((count(col(myY2))).alias(\"COUNT_DISTANCE\")).display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e7c4956-11b1-4acc-88c4-e461a99b9378"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# SPLIT DATA FOR TRAINING AND VALIDATION\nyear_train_val = 2018\ntrain_val2 = airlines3.filter(airlines3.YEAR <= year_train_val).cache()\ntest2 = airlines3.filter(airlines3.YEAR > year_train_val).cache()\n\n# CREATE SPLITS FOR CROSS VALIDATION - FIRST VALIDATION ON 2016, AND LAST VALIDATION ON 2018 - EXPANDING WINDOW STARTING WITH STEP ONE.\nd2 = createSplits(train_val2, 2016, 2018, 1, True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbf4c749-00c7-4fd4-ab04-be24ae4eaf9c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["## Current possible ways to handle categoricals in string indexer is 'error', 'keep', and 'skip'\nindexers2 = map(lambda c: StringIndexer(inputCol=c, outputCol=c+\"_idx\", handleInvalid = 'keep'), categoricals2)\nohes2 = map(lambda c: OneHotEncoder(inputCol=c + \"_idx\", outputCol=c+\"_class\", dropLast=True),categoricals2)\nimputers2 = Imputer(inputCols = numerics2, outputCols = numerics2)\n\n# Establish features columns\nfeatureCols2 = list(map(lambda c: c+\"_class\", categoricals2)) + numerics2\n\nmodel_matrix_stages2 = list(indexers2) + list(ohes2) + [imputers2] + \\\n                     [VectorAssembler(inputCols=featureCols2, outputCol=\"features\")]\n\n# Apply StandardScaler to create scaledFeatures\nscaler2 = StandardScaler(inputCol=\"features\",\n                        outputCol=\"scaledFeatures\",\n                        withStd=True,\n                        withMean=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4134372e-ee8c-4d53-a45d-9ec4cd8b6d81"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# RUN THIS FOR RANDOM FOREST\nrf2 = RandomForestClassifier(featuresCol = 'scaledFeatures', labelCol = 'label',\n                            featureSubsetStrategy='auto', \n                            impurity='entropy',    #gini\n                            maxDepth = 16,\n                            numTrees = 110,\n                            seed=123)\n\npipelineRF2 = Pipeline(stages=model_matrix_stages2+[scaler2]+[rf2])\n\nmodel_RF2 = pipelineRF2.fit(train_val2)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0929f610-e024-496f-8c19-858e43c1c555"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# GET PREDICTIONS -> DEP_DEL15, P0, P1, LABEL, PREDICTION\ntvprd2 = score(model_RF2, train_val2)\ntestprd2 = score(model_RF2, test_unbalanced)\n\nrfM2 = metricsdf([tvprd2, testprd2], [\"RF_train\", \"RF_test\"])\nrfM2"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"11d620fd-3529-419a-89bd-f0ca554251e5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Random Forest Confusion Matrix\ntestprd2.groupBy(\"DEP_DEL15\", \"prediction\").count().display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"53c6e6ad-5ba4-4c4c-aa25-c40be9e94d29"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# RUN THIS FOR RANDOM FOREST\nrf3 = RandomForestClassifier(featuresCol = 'features', labelCol = 'label',\n                            featureSubsetStrategy='auto', \n                            impurity='gini',    #gini\n                            maxDepth = 10,\n                            numTrees = 110,\n                            seed=123)\n\npipelineRF3 = Pipeline(stages=model_matrix_stages2+[rf3])\n\nmodel_RF3 = pipelineRF3.fit(train_val2)\n\n# GET PREDICTIONS -> DEP_DEL15, P0, P1, LABEL, PREDICTION\ntvprd3 = score(model_RF3, train_val2)\ntestprd3 = score(model_RF3, test2)\n\nrfM3 = metricsdf([tvprd3, testprd3], [\"RF_train\", \"RF_test\"])\nrfM3"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"696968e7-1a9a-44b8-9a28-260aa3e82f65"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa65a10c-7a3b-49f5-830c-2cd3a8df67a4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 11. Evaluate Where Model is Being Succeesful or Failing"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1ea0770-3495-40be-9056-573d280befe1"}}},{"cell_type":"code","source":["#categoricals = ['YEAR', 'QUARTER', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_CARRIER_AIRLINE_ID', 'ORIGIN_AIRPORT_ID', 'DEST_AIRPORT_ID', 'SEASON', 'WKDAY', 'DEPARTURE_Hour_CRS']\n\n# Helping Functions for Evaluating Models\ndef extract2(row):\n  return (row.SEASON,)+ (row.time_of_day_int,)+ (row.Cnn_Ranking_val,)+ (row.DEPARTURE_Hour_CRS,)+ (row.DEP_DEL15,) + tuple(row.probability.toArray().tolist()) +  (row.label,) + (row.prediction,)\n\ndef score2(model,data):\n  pred = model.transform(data).select('SEASON', 'time_of_day_int', 'Cnn_Ranking_val',\n                                      'DEPARTURE_Hour_CRS',\"DEP_DEL15\", \"probability\", \"label\", \"prediction\")\n  pred = pred.rdd.map(extract2).toDF(['SEASON', 'time_of_day_int', 'Cnn_Ranking_val',\n                                      'DEPARTURE_Hour_CRS',\"DEP_DEL15\", \"p0\", \"p1\", \"label\", \"prediction\"])\n  return pred \n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"909b7022-36a2-431f-b1f1-4cff4f03074b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# model_RF\n\ntestprd2 = score2(model_RF, test_unbalanced)\ntestprd2.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"53911700-aa7b-412b-ba49-355f79c70431"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def eval_mod_segment(df, attribute):\n  '''\n  Input:\n    df: dataframe including the predictions from a given model.\n    attribute: name of attribute to be used to evaluate the performance of the predictions of the model.\n  Output:\n    metric_df: dataframe including key metrics for all values of the attribute being evaluated.\n  '''\n  values = np.array(df.select(attribute).distinct().collect())\n  list = [int(v[0]) for v in values]\n  list.sort()\n  df_list = []\n  attr_names = []\n  for val in list:\n    print(\"Evaluating \",attribute,\": \", val)\n    dfTemp = df.filter(df[attribute] == int(val)).select(\"DEP_DEL15\", \"P0\", \"P1\",\"label\", \"prediction\").cache()\n    df_list.append(dfTemp)\n    attr_names.append(attribute+\"_\"+str(val))\n  metric_df = metricsdf(df_list, attr_names)\n  return metric_df"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1136c0c-91a3-4dba-b66c-44ac64cb1328"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### - Evaluate Model by Season"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6757176b-270a-4b86-a30a-4c395267cfc6"}}},{"cell_type":"code","source":["seasons_metric = eval_mod_segment(testprd2,\"SEASON\")\nseasons_metric"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d8f62e64-a7ef-4386-b4b8-727b276fbfde"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### - Evaluate Model by Mork Day (Weekend vs. Weekdays)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fab3b081-f4db-4bde-99e6-c692159b302d"}}},{"cell_type":"code","source":["wkday_metric = eval_mod_segment(testprd2,\"WKDAY\")\nwkday_metric"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83dd17f6-0e83-40c3-b3f0-ae3d5614f2af"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["month_metric = eval_mod_segment(testprd2,\"MONTH\")\nmonth_metric"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0247a27f-2831-4425-9371-aa529ec23259"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### - Evaluate Model by Day of Week"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97123f6a-a413-4ccd-adb0-f4ccdfcbcb9a"}}},{"cell_type":"code","source":["dow_metric = eval_mod_segment(testprd2,\"DAY_OF_WEEK\")\ndow_metric"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2fe52679-23de-4417-bc28-3389f3c01382"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### - Evaluate Model by Flight Departure Hour"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"98a32584-4932-4e70-b4f4-7ee18ec5e8b8"}}},{"cell_type":"code","source":["dh_crs_metric = eval_mod_segment(testprd2,\"DEPARTURE_Hour_CRS\")\ndh_crs_metric"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eb83b7be-2315-4fc1-9eb8-de55f21d569b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### - Evaluate Model by Quarter of the Year"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0c6076b-f5fd-4f9f-aa06-5203bba41af9"}}},{"cell_type":"code","source":["Q_metric = eval_mod_segment(testprd2,\"QUARTER\")\nQ_metric"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b494bf25-5c35-42b8-a2ca-fff833d7c212"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### - Evaluate Model by Time of the Day"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85ec3b74-f83b-42fc-8bb9-77a96feeeaf1"}}},{"cell_type":"code","source":["tod_metric = eval_mod_segment(testprd2,\"time_of_day_int\")\ntod_metric"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5bc48b40-ed30-448b-883f-ecafc19c43f1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### - Evaluate Model by Airport Rank by Number of Connections:\n###### Group 1: Top 5% of Airports, Group 2: Next 20%, Group 3: Next 25%, Group 4: Next 50%"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea4b62fa-7820-408c-88ee-71f218930474"}}},{"cell_type":"code","source":["cnn_rank_metric = eval_mod_segment(testprd2,\"Cnn_Ranking_val\")\ncnn_rank_metric"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"263cf8d5-7d2f-47c8-92f0-59f5ef8e1dab"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### - Evaluate Model by Airport Rank by Amount of Delay:\n###### Group 1: Top 5% of Airports, Group 2: Next 20%, Group 3: Next 25%, Group 4: Next 50%"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca7211d8-2017-4c45-8d66-cbfb5e01a403"}}},{"cell_type":"code","source":["delay_rank_metric = eval_mod_segment(testprd2,\"Delay_Ranking_val\")\ndelay_rank_metric"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"088fbdc0-e173-44f5-a75b-ae0cdd7c30b0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 12. Generate Models by Metric Segment (Season or Month)\n\nReference for LSVC - https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.LinearSVC.html"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5d2353b7-8b2c-4fd0-a96b-1fc1307ef8da"}}},{"cell_type":"code","source":["# SPLIT DATA FOR TRAINING AND VALIDATION\ndef train_test_segment(data, year_train_val, segment, segmentVal):\n  '''\n  INPUT:\n  year_train_val = Year for which data would be split between train and test.\n  segment = attribute would be used to select the specific data (i.e. \"SEASON\")\n  segmentVal = specific value for the segment that would be used to split data (i.e. 3 for season 3) \n  \n  OUTUT:\n  train and test split for developing models.\n  '''\n  \n  train_val_seg = data.filter((data.YEAR <= year_train_val) & (data[segment] == segmentVal)).cache()\n  test_seg = data.filter((data.YEAR > year_train_val) & (airlines2[segment] == segmentVal)).cache()\n\n  return train_val_seg, test_seg"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b1650944-e997-4842-8dbe-7856850e7bb8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Split data for Train, Validation and Test - \ntrain_val_seg, test_seg = train_test_segment(airlines2, 2018, \"SEASON\", 3)\n\n# CREATE SPLITS FOR CROSS VALIDATION - FIRST VALIDATION ON 2016, AND LAST VALIDATION ON 2018 - EXPANDING WINDOW STARTING WITH STEP ONE.\nd_seg = createSplits(train_val_seg, 2016, 2018, 1, True)\n\n# Type of Model: \"RF\" = Random Forest, \"LogR\" = Logistic Regression, \"GBT\" = Gradient Boosted Trees, \"LSVC\" = Linear Support Vector Classifier\nModel_seg = create_model(d_seg, model_matrix_stages, scaler, \"LogR\")\n\nseg_model = Model_seg.bestModel"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4b3755c-f65d-48ba-81d5-f648690da6e2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# GET PREDICTIONS -> DEP_DEL15, P0, P1, LABEL, PREDICTION\ntrainPredSeg = score(seg_model, train_val_seg)\ntestPredSeg = score(seg_model, test_seg)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c9af9916-dbcc-454d-8e7d-1ac2f744965b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["metric_seg = metricsdf([trainPredSeg, testPredSeg], [\"RF_trazLR_Season3\", \"RF_testLR_Season3\"])\nmetric_seg"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b64b43b-4125-4d7d-8d5a-4edeb9ae0f73"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def models_segment(data, model_matrix_stages, scaler, segment, ModelType):\n\n  '''\n  Input:\n    data: data to be evalauted.\n    matrix_stages and scaler for pipeline.\n    segment: variable to be used to generate models (for example: \"SEASON\")\n    ModelType: Name of Model to be generated - RF, GBT, LSVC, LogR.\n  Output:\n    metrics - performance for all models generated.\n    list of models - one model for each value of the attribute (segment) being evaluated\n    prediction list - list of dataframes with predictions.\n  '''\n  # Get values for Segment\n  values = np.array(data.select(segment).distinct().collect())\n  list = [int(v[0]) for v in values]\n  list.sort()\n  \n  model_list = []\n  name_list = []\n  pred_list = []\n  \n  for val in list:\n    # Split data for Train, Validation and Test\n    train_val_seg, test_seg = train_test_segment(airlines2, 2018, segment, val)\n    \n    # CREATE SPLITS FOR CROSS VALIDATION - FIRST VALIDATION ON 2016, AND LAST VALIDATION ON 2018 - EXPANDING WINDOW STARTING WITH STEP ONE.\n    d_seg = createSplits(train_val_seg, 2016, 2018, 1, True)\n  \n    Model_seg = create_model(d_seg, model_matrix_stages, scaler, ModelType)\n    seg_model = Model_seg.bestModel\n    \n    testPredSeg = score(seg_model, test_seg)\n    pred_list.append(testPredSeg)\n    name_list.append(segment+\"-\"+str(val))\n    model_list.append(Model_seg)\n    \n  metric_seg = metricsdf(pred_list, name_list)\n  return metric_seg, model_list, pred_list"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"998b656a-18f0-4a55-9f60-c76befb95832"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Type of Model: \"RF\" = Random Forest, \"LogR\" = Logistic Regression, \"GBT\" = Gradient Boosted Trees, \"LSVC\" = Linear Support Vector Classifier\nmetric_seg, model_list, pred_list = models_segment(airlines2, model_matrix_stages, scaler, \"time_of_day_int\", \"RF\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03221341-caae-48d6-82f2-f92b16a10bc6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["metric_seg"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e49c224-2ef2-499c-bd0b-1db495d7bdb7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 13. Random Forest - PCA"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94d85fb9-2c78-4871-a25e-2d4913b9fe1f"}}},{"cell_type":"code","source":["# Apply MinMaxScaler to create scaledFeatures\nscaler_pca = MinMaxScaler(inputCol=\"features\",\n                        outputCol=\"scaledFeatures\",\n                        min=0.0, max=1.0)\n\npca = PCA(k=150, inputCol=\"scaledFeatures\", outputCol = \"pca_features\")\n\n# Define a Random Forest model - WHEN using PCA\nrf_PCA = RandomForestClassifier(featuresCol = 'pca_features',  #Modify 'features' for scaled features\n                            labelCol = 'label',\n                            featureSubsetStrategy='auto', \n                            impurity='gini', \n                            maxBins=350,\n                            weightCol= 'weight',\n                            seed=None)\n\n# Set the Grid Search set of parameters\ngridpca = ParamGridBuilder()\\\n            .addGrid(rf_PCA.maxDepth, [5, 10])\\\n            .addGrid(rf_PCA.numTrees, [10, 15])\\\n            .build()\n\nevaluator = BinaryClassificationEvaluator()\n\n\n# Chain indexer and GBT in a Pipeline\npipeline_PCA = Pipeline(stages=model_matrix_stages+[scaler_pca]+[pca]+[rf_PCA])\n\n# Execute CrossValidator for model tuning\ncrossvalpca = CustomCrossValidator(estimator=pipeline,\n                                estimatorParamMaps=gridpca,\n                                evaluator=evaluator,\n                                splitWord = ('train', 'test'),\n                                cvCol = 'cv',\n                                parallelism=4)\n\n# Train the tuned model and establish our best model\ncv_rf_pca_Model = crossvalpca.fit(d)\nrf_pca_model = cv_rf_pca_Model.bestModel"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"675a2c2e-71f2-4e8c-a522-62e5c544b603"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["tvprd_pca = score(rf_pca_model, train_val)\ntestprd_pca = score(rf_pca_model, test)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70bc9bec-294d-41ee-bb62-83caff03c63c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["rfM_pca = metricsdf([tvprd_pca, testprd_pca], [\"RFpca_tr\", \"RFpca_test\"])\nrfM_pca"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a65e723d-4014-481e-807f-ca884b4455a2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Random Forest Confusion Matrix\ntestprd_pca.groupBy(\"label\", \"prediction\").count().display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1ccabb9e-c848-40ff-bba3-69d70f439274"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["metricsRFpca = MulticlassMetrics(testprd_pca.rdd.map(lambda x: (x[4], x[3])))\nrfM2pca = metricsdf2(metricsRFpca)\ndfMrfpca = pd.DataFrame({\"Rand_Forest\": list(rfM2pca.values())}, index = list(rfM2pca.keys()))\ndfMrfpca"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c443310-8eea-469d-8158-c568bed2027b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 14. PCA Analysis for Random Forest Model\n\nReference:  \n>- https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.PCA.html\n>- https://datascience-enthusiast.com/Python/PCA_Spark_Python_R.html"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31af3cec-9daf-4cc3-827a-f2ba8a7f30bf"}}},{"cell_type":"code","source":["# FOR PCA -> For OHE make sure to use droplast=True\n# MinMaxScaler\n\n## Current possible ways to handle categoricals in string indexer is 'error', 'keep', and 'skip'\nindexers = map(lambda c: StringIndexer(inputCol=c, outputCol=c+\"_idx\", handleInvalid = 'keep'), categoricals)\nohes = map(lambda c: OneHotEncoder(inputCol=c + \"_idx\", outputCol=c+\"_class\", dropLast=True),categoricals)\nimputers = Imputer(inputCols = numerics, outputCols = numerics)\n\n# Establish features columns\nfeatureCols = list(map(lambda c: c+\"_class\", categoricals)) + numerics\n\n# Build the stage for the ML pipeline\nmodel_matrix_stages = list(indexers) + list(ohes) + [imputers] + \\\n                     [VectorAssembler(inputCols=featureCols, outputCol=\"features\")]\n\n# Apply StandardScaler to create scaledFeatures\nscaler_pca = MinMaxScaler(inputCol=\"features\",\n                        outputCol=\"scaledFeatures\",\n                        min=0.0, max=1.0)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"772a5dea-12f6-4789-bc03-2520979a2d7f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["k = 150\npca = PCA(k=k, inputCol=\"scaledFeatures\", outputCol = \"pca_features\")\n# pca.setOutputCol(\"pca_output\")\n\n# Build our ML pipeline\npipelinePCA = Pipeline(stages=model_matrix_stages+[scaler_pca]+[pca])\n\n# Train model.  This also runs the indexer.\npca_model = pipelinePCA.fit(train_val)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"48840b5d-496f-41e8-905c-9af842ea1ef9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# pca_out = pca_model.transform(trainPCA)\n# pca_out.collect()[0].pca_output\n# pca_out.collect()[0].pca_features\n\n# Extract the PCA model\npcaM = pca_model.stages[-1]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ce1b6e4-4eda-460c-82f6-114b68547811"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Explained Variance\nexpVar1 = pcaM.explainedVariance\nexpVar1_array = np.array(expVar1)\nev_round = expVar1_array.round(3)*100"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f4f3c8b-5f03-491c-a273-06b796693745"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["ev_round"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"01be5e05-e379-4686-8ffb-0dc7c3e03c2c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#k = 100\ndef add_value_label(x_list,y_list):\n    for i in range(0, len(x_list)):\n      plt.text(i,y_list[i],y_list[i], ha=\"center\")\n\npc_list = range(1,k+1)\nfig = plt.figure(figsize=(10,7))\nax = fig.add_axes([0,0,1,1])\nadd_value_label(pc_list,ev_round.round(2))\nax.set_xlabel('Principal Components')\nax.set_ylabel('% Explained Variance')\nax.set_title('Explained Variance by Principal Component')\nax.bar(pc_list,ev_round.round(2))\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fcec089a-751a-4801-ac96-e5535504a171"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["cum_expVar = np.cumsum(expVar1_array)*100 \npc_list = range(1,k+1)\nfig = plt.figure(figsize=(10,7))\nax = fig.add_axes([0,0,1,1])\nax.set_xlabel('Principal Components')\nax.set_ylabel('% Explained Variance')\n#add_value_label(pc_list,cum_expVar.round(2))\nax.set_title('Cummulative Explained Variance')\nax.bar(pc_list,cum_expVar.round(2))\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd2b7c92-6eda-451c-bce5-646238624519"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def featureListPCA(data, categoricals, numerics):\n  featurelists = []\n  for f in categoricals:\n    \n    d = np.array(data.select(f).distinct().collect())\n    n = len(d)\n    \n    featurelists = featurelists + [f]*n\n  \n  for f in numerics:\n    featurelists = featurelists + [f]\n  \n  return featurelists"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7073f08d-845b-49a6-a159-294e55264319"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["flist = featureListPCA(train_val, categoricals, numerics)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"789a93bc-3eea-47ef-8e05-57f273975c35"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["pc_list = range(1,k+1)\npcs = np.round(pcaM.pc.toArray(),4)\ndf_pc = pd.DataFrame(pcs, columns = pc_list, index=flist).reset_index()\ndf_pc"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e392f61-3168-40d2-9695-0e7b483e211e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 15. Ensemble Learning Model\n\nThe Ensemble Learning Model combines the prediction results from several different models trained on the training data. In our case, we train the Base models Random Forest, Gradient Boosted Trees, and Support Vector machines on the `train_val` dataset which contains the 2015 through 2018 flights data. Next, we take the predictions from the model and then train a meta classifier (logistic regression) model to come up with the final classification.\n\nfrom pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.classification import LinearSVC\n\nfrom pyspark.mllib.evaluation import BinaryClassificationMetrics\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.mllib.evaluation import MulticlassMetrics"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7bfbfade-1346-4eb3-b982-141134b659af"}}},{"cell_type":"code","source":["def preprocess_data(train_df, meta_features=None):\n  \"\"\"\n  Return pre-processed meta-features \n  Args:\n    train_df - (spark DataFrame) training data\n    meta_features - (list) list of metafeatures columns\n  \"\"\"\n  ohes = OneHotEncoder(inputCols=meta_features, outputCols=['vec{}'.format(i) for i in range(len(meta_features))])\n  vec = VectorAssembler(inputCols=['vec{}'.format(i) for i in range(len(meta_features))], outputCol='meta_features')\n  pipeline = Pipeline(stages=[ohes, vec])\n  data_pipeline = pipeline.fit(train_df)\n  return data_pipeline.transform(train_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc7ee5ef-34cb-48c6-921b-a097054a84ff"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def ensemble_learning_model(gbt_model, rf_model,svc_model, train_val, meta_features):\n  \"\"\"\n    Return predictions of Stacking Ensemble Learning Model in Spark DataFrame.\n    Args:\n        gbt_model - Gradient Boosted Tree spark fitted model\n        rf_model - Random Forest spark fitted model\n        meta_classifier - Logistic Regression fitted model\n        meta_features - (list) meta feature prediction column names\n        train_val - (spark DataFrame) training data\n  \"\"\"\n  # get predictions from each model\n  data1 = rf_model.transform(train_val).select(categoricals+numerics+ [\"prediction\",\"label\"]).withColumnRenamed('prediction', 'rf_pred')\n  data2 = gbt_model.transform(data1).select(categoricals+numerics+[\"prediction\",\"label\",\"rf_pred\"]).withColumnRenamed('prediction', 'gbt_pred')\n  data3 = svc_model.transform(data2).select(categoricals+numerics+[\"label\", \"prediction\",\"rf_pred\", 'gbt_pred']).withColumnRenamed('prediction', 'svc_pred')\n  \n  \n  # pre-process meta-features\n  preds = preprocess_data(data3, meta_features).cache()\n  \n  # create meta-classifier\n  lr = LogisticRegression(featuresCol='meta_features', labelCol='label', predictionCol='meta_pred', maxIter=20, regParam=1., elasticNetParam=0)\n  meta_classifier = lr.fit(preds)\n  meta_preds = meta_classifier.transform(preds)\n  \n  \n  return meta_classifier, meta_preds\n    \n    "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"292158f7-be26-45a8-a4c6-3005b1514860"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def predict_ensemble(gbt_model, rf_model,svc_model, meta_classifier,meta_features, test_df):\n  \"\"\"\n      Return predictions of Stacking Ensemble Learning Model in Spark DataFrame.\n      Args:\n          gbt_model - Gradient Boosted Tree spark fitted model\n          rf_model - Random Forest spark fitted model\n          meta_classifier - Logistic Regression fitted model\n          meta_features - (list) meta feature prediction column names\n          test_df - (spark DataFrame) Data Holdout\n  \"\"\"\n  # get predictions from each model\n  data1 = rf_model.transform(test_df).select(categoricals+numerics+ [\"prediction\",\"label\"]).withColumnRenamed('prediction', 'rf_pred')\n  data2 = gbt_model.transform(data1).select(categoricals+numerics+[\"prediction\",\"label\",\"rf_pred\"]).withColumnRenamed('prediction', 'gbt_pred')\n  data3 = svc_model.transform(data2).select(categoricals+numerics+[\"label\", \"prediction\",\"rf_pred\", 'gbt_pred']).withColumnRenamed('prediction', 'svc_pred')\n\n  # pre-process meta-features\n  preds = preprocess_data(data3, meta_features).cache()\n  meta_preds = meta_classifier.transform(preds)\n  return meta_preds"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5f95244-996a-4f47-970d-64214807bb8e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def get_metrics(df, preds, labels):\n  \"\"\"\n        Return evaluation metrics\n        Args:\n            df - model transformed dataframe\n            preds - (str) prediction column\n            labels - label column\n  \"\"\"\n  predmet = df.select(labels, preds)\n  metricsmet = MulticlassMetrics(predmet.rdd.map(lambda x: (x[1], x[0])))\n  mmet = metricsdf2(metricsmet)\n  dfmet = pd.DataFrame({\"Ensemble\": list(mmet.values())}, index = list(mmet.keys()))\n  return dfmet\n  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"50c440b4-9bae-442c-b856-9da3bc347db6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Loading in Based Models if they already exist\n# Loading a Random Forest Saved Model\nmodel_path = f\"{blob_url}/models/rf_model\"\nrf_modelSAVED = rf_model.load(model_path)\n\n# Loading a Gradient Boosted Tree Saved Model\nmodel_path = f\"{blob_url}/models/gbt_model\"\ngbt_modelSAVED = gbt_model.load(model_path)\n\n# Loading a Log Regression Saved Model\nmodel_path = f\"{blob_url}/models/lsvc_model\"\nlsvc_modelSAVED = lsvc_model.load(model_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2c90f9fc-1f1c-4aae-a4ff-8eb0116a1d46"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Train meta classifier\n# model_RF, model_GBT, model_LSVC, model_LR, model_RF2\nmeta_classifier, meta_preds = ensemble_learning_model(model_GBT, model_RF2,model_LSVC, train_val, ['rf_pred','gbt_pred','svc_pred'])\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef0d2549-7453-4ad0-8a12-f5fb09ec9bd2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Get evaluation metrics\ndf_meta = get_metrics(meta_preds,\"meta_pred\",\"label\")\ndf_meta.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8f5db50c-6114-46cd-9a8c-576e144d7e49"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["meta_preds2 = predict_ensemble(model_GBT, model_RF,model_LSVC, meta_classifier,['rf_pred','gbt_pred','svc_pred'], test_unbalanced)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e59c33c9-5f3b-47a5-9357-55468ad4d074"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["df_meta2 = get_metrics(meta_preds2,\"meta_pred\",\"label\")\ndf_meta2.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"af81bc81-119f-4a13-94d0-1435cf51a56e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Random Forest Confusion Matrix\n#testprd2.groupBy(\"DEP_DEL15\", \"prediction\").count().display()\ndf_meta2.groupBy(\"label\", \"meta_pred\").count().display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6c3e5c0-3317-4d28-a68f-72e592617d0f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["test.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ff14e61-a26b-4df7-8fd3-f47f88d91e1a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["predrf = rf_modelSAVED.transform(test).select(\"DEP_DEL15\", \"prediction\")\nmetricsrf = MulticlassMetrics(predrf.rdd.map(lambda x: (x[1], x[0])))\nmrf = metricsdf2(metricsrf)\ndfrf = pd.DataFrame({modelName: list(mrf.values())}, index = list(mrf.keys()))\ndfrf"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"86d16d1d-b6e4-4fa9-a5c6-f40f8c53672f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Loading a Gradient Boosted Tree Saved Model\nmodel_path = f\"{blob_url}/models/gbt_model\"\ngbt_modelSAVED = gbt_model.load(model_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d99957e6-19ad-4c2c-aba4-48f1f7f17a5c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["predrf = gbt_modelSAVED.transform(test).select(\"DEP_DEL15\", \"prediction\")\nmetricsrf = MulticlassMetrics(predrf.rdd.map(lambda x: (x[1], x[0])))\nmrf = metricsdf2(metricsrf)\ndfrf = pd.DataFrame({modelName: list(mrf.values())}, index = list(mrf.keys()))\ndfrf"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f8f49176-9105-4a43-bf4e-fb141b758b8c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Loading a Log Regression Saved Model\nmodel_path = f\"{blob_url}/models/lsvc_model\"\nlsvc_modelSAVED = lsvc_model.load(model_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"524c09d1-d8f0-4c46-b8e3-68894154fedb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["predrf = lsvc_modelSAVED.transform(test).select(\"DEP_DEL15\", \"prediction\")\nmetricsrf = MulticlassMetrics(predrf.rdd.map(lambda x: (x[1], x[0])))\nmrf = metricsdf2(metricsrf)\ndfrf = pd.DataFrame({modelName: list(mrf.values())}, index = list(mrf.keys()))\ndfrf"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2c7e946-5863-4157-aa5a-0cec65429539"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#select(myX + [myY, \"DEP_DELAY_NEW\", \"DEP_DELAY\"])\n\n\ndata1 = rf_modelSAVED.transform(train_val).select(categoricals+numerics+[\"prediction\",\"label\"]).withColumnRenamed('prediction', 'rf_pred')\ndata1.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e0ca4aaf-1a69-4383-b68b-30477148d0c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["data1 = rf_modelSAVED.transform(train_val).select(categoricals+numerics+[\"prediction\",\"label\"]).withColumnRenamed('prediction', 'rf_pred')\ndata2 = gbt_modelSAVED.transform(data1).select(categoricals+numerics+[\"prediction\",\"label\",\"rf_pred\"]).withColumnRenamed('prediction', 'gbt_pred')\ndata3 = lsvc_modelSAVED.transform(data2).select(categoricals+numerics+[\"label\", \"prediction\",\"rf_pred\", 'gbt_pred']).withColumnRenamed('prediction', 'svc_pred')\ndata3.display()\n\n\npreds = preprocess_data(data3, ['rf_pred','gbt_pred','svc_pred'])\npreds.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c3b01c7-5c83-4c5e-b9ec-5379461f636f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["preds = preprocess_data(data3, ['rf_pred','gbt_pred','svc_pred'])\npreds.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5c145f03-c118-44f1-81fa-b9fe36608769"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["lr = LogisticRegression(featuresCol='meta_features', labelCol='label', predictionCol='meta_pred', maxIter=20, regParam=1., elasticNetParam=0)\nmeta_classifier = lr.fit(preds)\nmeta_preds = meta_classifier.transform(preds)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"95efbd89-9c4e-4de4-960c-31f83fa4fe62"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["predrf = meta_preds.select(\"label\", \"meta_pred\")\nmetricsrf = MulticlassMetrics(predrf.rdd.map(lambda x: (x[1], x[0])))\nmrf = metricsdf2(metricsrf)\ndfrf = pd.DataFrame({modelName: list(mrf.values())}, index = list(mrf.keys()))\ndfrf"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64be9ad0-d8c5-41b5-8373-c1afc201ff1b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def ensemble_learning_model(cv_train_df, train_val_df, meta_features):\n    \"\"\"\n    Return the Gradient Boosted Tree, Random Forest, Support Vector Machine, and Meta Classifier algorithms\n    \n    Args:\n        cv_train_df - (dict) dictionary of Spark Dataframes {'df1': sparkdf1, 'df2':sparkdf2 ...}\n        train_val_df - {SparkDF} Training data (Features and Labels)\n        meta_features - (list) of meta features column names\n    \"\"\"\n  \n    # Loading in Based Models if they already exist\n    # Loading a Random Forest Saved Model\n    model_path = f\"{blob_url}/models/rf_model\"\n    rf_model = rf_model.load(model_path)\n    # Loading a Gradient Boosted Tree Saved Model\n    model_path = f\"{blob_url}/models/gbt_model\"\n    gbt_model = gbt_model.load(model_path)\n    # Loading a Log Regression Saved Model\n    model_path = f\"{blob_url}/models/lsvc_model\"\n    svc_model = svc_model.load(model_path)\n        \n    # Get the meta features which are predictions of the baseline models\n    train_dt = preprocess_data(train_val_df).cache()\n    \n    # Transform data to include predictions (meta_features)\n    preds = svc_model.transform(gbt_model.transform(rf_model.transform(train_dt) \\\n                                .drop('rawPrediction','probability')) \\\n                                .drop('rawPrediction','probability')) \\\n                                .drop('rawPrediction','probability')\n    # Define meta features\n    meta_fts = meta_features\n    # Preprocess meta features using One Hot Encoding and Vectorizer\n    preds = preprocess_data(preds, meta_features = meta_fts).cache()\n    \n    # Train meta classifier (Logistic Regression)\n    lr = LogisticRegression(featuresCol='meta_features', labelCol='label', predictionCol='meta_pred', maxIter=20, regParam=1., elasticNetParam=0)\n    meta_classifier = lr.fit(preds)\n    meta_preds = meta_classifier.transform(preds)\n    return gbt_model, rf_model,svc_model, meta_classifier, meta_preds\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84e0cc19-dc2a-4d21-b91b-660a020be505"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Reference:\n>- https://pages.databricks.com/rs/094-YMS-629/images/02-Delta%20Lake%20Workshop%20-%20Including%20ML.html\n>- https://databricks.com/blog/2018/08/09/loan-risk-analysis-with-xgboost-and-databricks-runtime-for-machine-learning.html\n>- https://spark.apache.org/docs/latest/ml-features\n\nOther reference on Delta lakes:\n>- https://towardsdatascience.com/delta-lake-with-spark-what-and-why-6d08bef7b963  \n>- https://databricks.com/notebooks/gallery/GettingStartedWithSparkMLlib.html  \n>- https://pages.databricks.com/rs/094-YMS-629/images/02-Delta%20Lake%20Workshop%20-%20Including%20ML.html\n\nReference Random Forest:  \n>- https://towardsdatascience.com/a-guide-to-exploit-random-forest-classifier-in-pyspark-46d6999cb5db\n>- https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.mllib.tree.RandomForest.html\n\nUsing weight fro unbalance data:\n>- https://www.datatrigger.org/post/spark_3_weighted_random_forest/"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aeb94273-c1c8-434a-9a8c-fd19bd753749"}}},{"cell_type":"markdown","source":["##### - Logistic Regression Notes  \n  \n>- We will be using the Apache Spark pre-installed GLM and GBTClassifier models\n>- GLM is in reference to generalized linear models; the Apache Spark logistic regression model is a special case of a generalized linear model\n>- Use BinaryClassificationEvaluator, CrossValidator, and ParamGridBuilder to tune our models.\n\n###### For this initial pipeline we focused on Logistic Regression, using the following formula:\n\n$$\nP(\\text{Delay}) = \\frac{1}{1 + e^{-(\\beta_{0} + \\sum_{i=1}^{n}(\\beta{i} * \\text{Flight}_{i} )+ \\sum_{j=1}^{m}(\\beta{j} * \\text{Weather}_{j} ) + \\sum_{k=1}^{l}(\\beta{k} * \\text{Others}_{k} ))}}\n$$\n\nIn feature model we will use Linear Regression:\n\n$$\n\\text{Delay in minutes} = \\beta_{0} + \\sum_{i=1}^{n}(\\beta{i} * \\text{Flight}_{i} )+ \\sum_{j=1}^{m}(\\beta{j} * \\text{Weather}_{j} ) + \\sum_{k=1}^{l}(\\beta{k} * \\text{Others}_{k} )\n$$\n\nFinally, we will explore other Machine Learning Algorithms (to be defined)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"017d61f4-b61e-4087-9265-1ec7b8b42180"}}},{"cell_type":"markdown","source":["##### Model Metrics & Performance\n###### Performance Metrics Using Map/Reduce  \n\n**Positive** - defined as \"being delayed\"\n\n>- **False Positive:** Predicted a delay, but flight was not delayed.  The potential implications are:\n>>- Passenger get's stress, and may start looking for alternatives.  \n>>- Passenger may start complaining and express negatively about the airline (even before the delay)\n>>- Paasenger may try to cancel (it he/she has flexibility)\n>>- May lead to some frustration, but if flight is not delayed, he/she may be pleasently surprised.\n\n>- **False Negative:** Predicted No Delay, but flight was delayed.  Some consequences are: \n>>- Passenger is frustrated. He/she thought things were OK, and now the flight is delayed.  No time to change anything.\n>>- Passenger feels helpless - he/she can't do anything to manage situation.\n>>- High reputation cost for airline\n\nIf there is more weight for `False Negative`, there is a need to minimize `False Negatives`, thus we want to minimize **Recall**.\n\n**How do we communicate the delay?** For example, a delay of more than 30 minutes is likely (or very likely)\n>- Include a sense of time of delay - how much time delay? \n>- Include a sense of probability - likelyhood/confidence on the predicted event.\n\nThrough the right communication approach we manage potential False Positives, but try to minimize False Negatives. Thus, we need to give more weight to `Recall`, thus, performance metric will focus on `F2-score`. \n\n##### F-Beta Coefficient: Alternatives:\n>- Interested in an F-measure with more attention put on precision, such as when false positives are more important to minimize, but false negatives are still important.\n>- Interested in an F-measure with more attention put on recall, such as when false negatives are more important to minimize, but false positives are still important.\n\n$$\nFbeta = \\frac{((1 + beta^2) * Precision * Recall)} {(beta^2 * Precision )+ Recall)}\n$$\n\n>>- F0.5-Measure (beta=0.5): More weight on precision, less weight on recall.\n>>- F1-Measure (beta=1.0): Balance the weight on precision and recall.\n>>- F2-Measure (beta=2.0): Less weight on precision, more weight on recall\n\n\nReference:\n>- https://machinelearningmastery.com/fbeta-measure-for-machine-learning/#:~:text=The%20F2%2Dmeasure%20is%20calculated,(4%20*%20Precision%20%2B%20Recall)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc15c7a6-88b8-46a7-9a09-4bad0c894584"}}},{"cell_type":"markdown","source":["##### Accuracy Demonstrated (literature)\n\n80.44% SVR\n\nReference:  \n>- https://journalofbigdata.springeropen.com/articles/10.1186/s40537-020-00380-z#:~:text=The%20results%20have%20shown%20SVR,impact%20on%20the%20mode%20performance.  \n>- https://medium.com/analytics-vidhya/using-machine-learning-to-predict-flight-delays-e8a50b0bb64c\n\nRecall - ~80 to 84%"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f46756f8-b3d1-48d7-841a-c9667e4c450a"}}},{"cell_type":"markdown","source":["###### - OLD CODE - GRID SEARCH"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe2f9d1e-01c6-4916-bd98-8562ea7de84d"}}},{"cell_type":"code","source":["# Sliding Window:\n# 2015 2016 - 2017\n# 2016 2017 - 2018\n# 2017 2018 - 2019\n\ndatasplits = {}\ni = 2015   # For YEAR 2015\ndatasplits[i] = {\"train\" : airlines2.filter(airlines2.YEAR <= i).cache(),\n                   \"valid\": airlines2.filter(airlines2.YEAR == i+1).cache()}\ni += 1  # FOR YEAR 2016\ndatasplits[i] = {\"train\" : airlines2.filter(airlines2.YEAR <= i).cache(),\n                   \"valid\": airlines2.filter(airlines2.YEAR == i+1).cache()}\n\ni += 1  # FOR FOR YEAR 2017\ndatasplits[i] = {\"train\" : airlines2.filter(airlines2.YEAR <= i).cache(),\n                   \"valid\": airlines2.filter(airlines2.YEAR == i+1).cache()}\n\ni += 1  # FOR YEAR 2018\ndatasplits[i] = {\"train\" : airlines2.filter(airlines2.YEAR <= i).cache(),\n                   \"valid\": airlines2.filter(airlines2.YEAR == i+1).cache()}\n\n# i += 1  # FOR MONTH 5\n# datasplits[i] = {\"train\" : airlines2.filter(airlines2.MONTH <= i).cache(),\n#                    \"valid\": airlines2.filter(airlines2.MONTH == i+1).cache()}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62318d68-7d33-40e7-9192-504c0c81017d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def Mmetric(model_matrix_stages, datasplits, scaler, numTrees, maxDepth, weigth, metric, verbose, pca_flag, k):\n  \n  keys = datasplits.keys()\n  metricL = []\n  metricsL = []\n  maverage = 0\n  #print(\"***** Evaluating - numTress: \",numTrees, \" maxDepth: \",maxDepth, \" *****\")\n  for key in keys:\n    #if verbose: print(\"PROCESSING PARTITION *********\", key)\n    train_rf = datasplits[key][\"train\"]\n    valid_rf = datasplits[key][\"valid\"]\n\n    # Chain indexer and GBT in a Pipeline\n    if pca_flag:\n      # Apply MinMaxScaler to create scaledFeatures\n      scaler_pca = MinMaxScaler(inputCol=\"features\",\n                              outputCol=\"scaledFeatures\",\n                              min=0.0, max=1.0)\n      \n      rf_pca = RandomForestClassifier(featuresCol = 'scaledFeatures', \n                            labelCol = 'label',\n                            featureSubsetStrategy='auto', \n                            impurity='gini', \n                            numTrees = numTrees,\n                            maxDepth= maxDepth, \n                            maxBins=305,\n                            weightCol=weigth,\n                            seed=None)\n      pca = PCA(k=k, inputCol=\"features\", outputCol = \"pca_features\")\n      pca.setOutputCol(\"pca_output\")\n      pipeline = Pipeline(stages=model_matrix_stages+[scaler_pca]+[pca]+[rf_pca])\n    else:\n      rf = RandomForestClassifier(featuresCol = 'scaledFeatures', \n                            labelCol = 'label',\n                            featureSubsetStrategy='auto', \n                            impurity='gini', \n                            numTrees = numTrees,\n                            maxDepth= maxDepth, \n                            maxBins=305,\n                            weightCol=weigth,\n                            seed=None)\n\n      pipeline = Pipeline(stages=model_matrix_stages+[scaler]+[rf])\n\n    # Train model.  This also runs the indexer.\n    rf_model = pipeline.fit(train_rf)    \n\n    rf_valid = score(rf_model, valid_rf)\n    \n    c, mrf_valid = model_metric(rf_valid)\n    metricL.append(mrf_valid[metric])\n    metricsL.append(mrf_valid)\n    maverage += mrf_valid[metric]\n    \n  avgmetric = maverage/len(keys)\n  if verbose:\n    print(\"Ntrees: \",numTrees, \" Depth: \",maxDepth, \"W: \", weigth, \"Avg \",metric, \": \", avgmetric, \" list: \", metricL)\n  return avgmetric, metricL"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"18c7b97d-792e-4406-9f62-445063c5238c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# GRID SEARCH FOR RANDOM FOREST - TWO PARAMETERS\ndef GS_rf(model_matrix_stages, datasplits, scaler, numTrees, maxDepth, weights, metric, verbose, pca, k):\n  \n  metrics_rf = {}\n  i = 1\n  \n  maxmetric = 0\n  bestparam = []\n  \n  for nt in numTrees:\n    for md in maxDepth:\n      for w in weights:\n        modmetric, modmetricL = Mmetric(model_matrix_stages, datasplits, scaler, nt, md, w, metric, verbose, pca, k)\n        metrics_rf[i] = {\"metric\": modmetric, \"parameters\": [nt, md, w], \"metric list\": modmetricL}\n        if modmetric > maxmetric:\n          maxmetric = modmetric\n          bestparam = [nt, md, w]\n          #if verbose: print(\"Current best metric: \",maxmetric, \" Best parameters: \", betparam)\n        i += 1\n  \n  return metrics_rf, maxmetric, bestparam"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b3030e6a-7d64-46fa-9649-c7fc74b573c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["numTrees = [20, 25, 30, 35, 40]\nmaxDepth = [4, 5, 6, 8, 10, 15]\nweights = ['weight']\n\n# numTrees = [5, 10, 15, 20]\n# maxDepth = [3, 4, 5, 6]\n# weights = ['weight', 'weight1', 'weight2']\n\n# numTrees = [20,25]\n# maxDepth = [4, 5]\n# weights = ['weight']\n\n# numTrees = [15, 20]\n# maxDepth = [4, 5]\n\nGS_output2, maxmetric2, bestparam2 = GS_rf(model_matrix_stages, datasplits, scaler, numTrees, maxDepth, weights, \"f2_score\",True, True, 3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"291ba433-028a-4eab-8aa8-e568d1ddb7f2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(maxmetric2, bestparam2)\n\npdf = pd.DataFrame(GS_output2)\npdf"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7704defb-457f-4c49-b76a-04c319a09e49"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### - ADDITIONAL CODE -NOT USED"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"37bbc5ab-d2e1-46e4-aa74-83ad5bf16c7b"}}},{"cell_type":"code","source":["# OLD CODE\nglm_train = score(glm_model, train)\nglm_valid = score(glm_model, valid)\ngbt_train = score(gbt_model, train)\ngbt_valid = score(gbt_model, valid)\n\nglm_train.createOrReplaceTempView(\"glm_train\")\nglm_valid.createOrReplaceTempView(\"glm_valid\")\ngbt_train.createOrReplaceTempView(\"gbt_train\")\ngbt_valid.createOrReplaceTempView(\"gbt_valid\")\n\n\n# print (\"GLM Training AUC ROC :\" + str(auc(glm_train)))\n# print (\"GLM Validation AUC ROC :\" + str(auc(glm_valid)))\n# print (\"GBT Training AUC ROC :\" + str(auc(gbt_train)))\n# print (\"GBT Validation AUC ROC :\" + str(auc(gbt_valid)))\n# print (\"************************************************\")\n# print (\"GLM Training AUC PR :\" + str(pr(glm_train)))\n# print (\"GLM Validation AUC PR :\" + str(pr(glm_valid)))\n# print (\"GBT Training AUC PR :\" + str(pr(gbt_train)))\n# print (\"GBT Validation AUC PR :\" + str(pr(gbt_valid)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"12b4f0a3-0847-43e1-bcaa-6ebd9419d5e5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["\ndef auc(pred):\n  metric = BinaryClassificationMetrics(pred.select(\"p1\", \"label\").rdd)\n  return metric.areaUnderROC\n\ndef pr(pred):\n  metric = BinaryClassificationMetrics(pred.select(\"p1\", \"label\").rdd)\n  return metric.areaUnderPR"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"68c88095-df8d-4cdb-925b-ac191fa249db"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def preprocess_data(train_df, meta_features=None):\n    if meta_features == None:\n      indexers = map(lambda c: StringIndexer(inputCol=c, outputCol=c+\"_idx\", handleInvalid = 'keep'), categoricals)\n      imputers = Imputer(inputCols = numerics, outputCols = numerics)\n      featureCols = list(map(lambda c: c+\"_idx\", categoricals)) + numerics\n      # Define vector assemblers\n      scaler = StandardScaler(inputCol=\"features\",\n                            outputCol=\"scaledFeatures\",\n                            withStd=True,\n                            withMean=True)\n\n      model_matrix_stages = list(indexers) + [imputers] + \\\n                         [VectorAssembler(inputCols=featureCols, outputCol=\"features\")]\n      # Data Preprocessing Pipeline\n      pipeline = Pipeline(stages=model_matrix_stages+[scaler])\n    else:\n        ohes = OneHotEncoder(inputCols=meta_features, outputCols=['vec{}'.format(i) for i in range(len(meta_features))])\n        vec = VectorAssembler(inputCols=['vec{}'.format(i) for i in range(len(meta_features))], outputCol='meta_features')\n        pipeline = Pipeline(stages=[ohes, vec])\n        \n    data_pipeline = pipeline.fit(train_df)\n    return data_pipeline.transform(train_df)\n "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"817f72d2-3c77-40f1-a68b-b6e43ea4e4f2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ffe5f5fa-f5de-492b-92ab-666f0ff083c2"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"team14_pipeline_implementation","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1858507102428825}},"nbformat":4,"nbformat_minor":0}
