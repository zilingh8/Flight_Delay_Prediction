{"cells":[{"cell_type":"markdown","source":["# Exploration and Graphs\n\n#### Team 14: Carlos Moreno, Elizabeth Khan, Jagan Lakshmipathy, and Ziling Huang\n\n\n__Summary:__\nA flight network can be represented by a Power-Law Distribution with uneven distributions of nodes and relationships. Most airports have few relationships but some airports have a lot which creates hub-and-spoke structures. Using a traditional analytics approach may obscure patterns due to the skew and hence graph analytics are used to keep the focus on relationships. \n\nThrough Centrality Algorithms like Pagerank we can understand which airport nodes are most important in the flight traffic network.\nIn Community Detection Algorithms, we find airport communities and uncover hubs to study cascading effects of delays and weather."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"923184bc-b6e1-4101-9628-6e1e218c071c"}}},{"cell_type":"markdown","source":["##Setup and import libraries"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1d87dcd-1d7f-4ede-9252-c434000edfe1"}}},{"cell_type":"code","source":["#https://www.analyticsvidhya.com/blog/2021/08/best-practices-and-performance-tuning-activities-for-pyspark/\n#Create spark session with required configuration\n \nfrom pyspark.sql import SparkSession,SQLContext\nsql_jar=\"/path/to/sql_jar_file/sqljdbc42.jar\"\nspark_snow_jar=\"/usr/.../snowflake/spark-snowflake_2.11-2.5.5-spark_2.3.jar\"\nsnow_jdbc_jar=\"/usr/.../snowflake/snowflake-jdbc-3.10.3.jar\"\noracle_jar=\"/usr/path/to/oracle_jar_file//v12/jdbc/lib/oracle6.jar\"\nspark=(SparkSession\n.builder\n.master('yarn')\n.appName('Spark job new_job')\n.config('spark.driver.memory','10g')\n.config('spark.submit.deployMode','client')\n.config('spark.executor.memory','15g')\n.config('spark.executor.cores',4)\n.config('spark.yarn.queue','short')\n.config('spark.jars','{},{},{},{}'.format(sql_jar,spark_snow_jar,snow_jdbc_jar,oracle_jar))\n.enableHiveSupport()\n.getOrCreate())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0976b62d-9d45-41b1-9031-15a92429453a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import *\nimport pyspark.sql.functions as F\nfrom pyspark.sql.types import IntegerType,BooleanType,DateType,DoubleType,FloatType\nimport networkx as nx\n\nfrom pyspark.sql.types import *\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql import Row\nfrom pyspark.rdd import portable_hash\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import to_timestamp, to_date\nfrom pyspark.sql.functions import substring\n\nimport pandas as pd\nimport numpy as np\nimport math as math\nimport time\nimport datetime\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\nimport matplotlib.ticker as mtick\nimport seaborn as sns\nfrom graphframes import *\nimport geopandas as gpd\nimport plotly as plotly\n\nfrom heatmap import heatmap, corrplot\n\npd.set_option(\"display.max_rows\", 999)\npd.set_option(\"display.max_columns\", 200)\n\n\nfrom pyspark.ml import *\nfrom pyspark.ml.linalg import *\nfrom pyspark.ml.stat import *\nfrom pyspark.ml.feature import *\nfrom pyspark.sql.window import *\n\nimport neo4j \nfrom neo4j import GraphDatabase\n\nfrom bokeh.sampledata import us_states\nfrom bokeh.plotting import *\nimport csv\n\nfrom graphframes.lib import AggregateMessages as AM\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import *\nfrom operator import itemgetter\n\n#Blob credentials\nblob_container = \"cemgr14c\" # The name of your container created in https://portal.azure.com\nstorage_account = \"cemgr14\" #The name of your Storage account created in https://portal.azure.com\nsecret_scope = \"w261gr14\" # The name of the scope created in your local computer using the Databricks CLI\nsecret_key = \"keygr14\" # The name of the secret key created in your local computer using the Databricks CLI\nblob_url = f\"wasbs://{blob_container}@{storage_account}.blob.core.windows.net\"\nmount_path = \"/mnt/mids-w261\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9b6991f-d079-40fd-81a0-5bc793f1dd9d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#pandas udf\nspark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5de06e8-d140-41a3-a7f0-3db790a8c245"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# SAS Token\n\nspark.conf.set(\n  f\"fs.azure.sas.{blob_container}.{storage_account}.blob.core.windows.net\",\n  dbutils.secrets.get(scope = secret_scope, key = secret_key)\n)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c671e9c4-8fd4-493e-810c-80dc1e2647b2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Inspect the Mount's Final Project folder \ndisplay(dbutils.fs.ls(f\"{mount_path}/datasets_final_project\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa55591d-4143-4189-8741-28af0c435de1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/mnt/mids-w261/datasets_final_project/airlines/","airlines/",0],["dbfs:/mnt/mids-w261/datasets_final_project/airlines_data/","airlines_data/",0],["dbfs:/mnt/mids-w261/datasets_final_project/parquet_airlines_data/","parquet_airlines_data/",0],["dbfs:/mnt/mids-w261/datasets_final_project/parquet_airlines_data_3m/","parquet_airlines_data_3m/",0],["dbfs:/mnt/mids-w261/datasets_final_project/parquet_airlines_data_6m/","parquet_airlines_data_6m/",0],["dbfs:/mnt/mids-w261/datasets_final_project/stations_data/","stations_data/",0],["dbfs:/mnt/mids-w261/datasets_final_project/weather_data/","weather_data/",0],["dbfs:/mnt/mids-w261/datasets_final_project/weather_data_6_hr/","weather_data_6_hr/",0],["dbfs:/mnt/mids-w261/datasets_final_project/weather_data_single/","weather_data_single/",0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/mnt/mids-w261/datasets_final_project/airlines/</td><td>airlines/</td><td>0</td></tr><tr><td>dbfs:/mnt/mids-w261/datasets_final_project/airlines_data/</td><td>airlines_data/</td><td>0</td></tr><tr><td>dbfs:/mnt/mids-w261/datasets_final_project/parquet_airlines_data/</td><td>parquet_airlines_data/</td><td>0</td></tr><tr><td>dbfs:/mnt/mids-w261/datasets_final_project/parquet_airlines_data_3m/</td><td>parquet_airlines_data_3m/</td><td>0</td></tr><tr><td>dbfs:/mnt/mids-w261/datasets_final_project/parquet_airlines_data_6m/</td><td>parquet_airlines_data_6m/</td><td>0</td></tr><tr><td>dbfs:/mnt/mids-w261/datasets_final_project/stations_data/</td><td>stations_data/</td><td>0</td></tr><tr><td>dbfs:/mnt/mids-w261/datasets_final_project/weather_data/</td><td>weather_data/</td><td>0</td></tr><tr><td>dbfs:/mnt/mids-w261/datasets_final_project/weather_data_6_hr/</td><td>weather_data_6_hr/</td><td>0</td></tr><tr><td>dbfs:/mnt/mids-w261/datasets_final_project/weather_data_single/</td><td>weather_data_single/</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Inspect our Team's data blob \ndisplay(dbutils.fs.ls(f\"{blob_url}\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e2a3824-1858-485b-bf57-40eda5fad323"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_joins_sel/","airline_joins_sel/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_joins_sel.delta/","airline_joins_sel.delta/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_joins_sel_CEM/","airline_joins_sel_CEM/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_pr_cem.delta/","airline_pr_cem.delta/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_rank_CEM_CAR1.delta/","airline_rank_CEM_CAR1.delta/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_CEM_CAR1.delta/","airline_test_CEM_CAR1.delta/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_sel/","airline_test_sel/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_sel.delta/","airline_test_sel.delta/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_sel_CEM.delta/","airline_test_sel_CEM.delta/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_sel_CEM_CAR.delta/","airline_test_sel_CEM_CAR.delta/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_sel_CEM_CAR1.delta/","airline_test_sel_CEM_CAR1.delta/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_sel_CEM_carlos.delta/","airline_test_sel_CEM_carlos.delta/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_sel_jagan.delta/","airline_test_sel_jagan.delta/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airplanes_weather_final_5yr_EZ/","airplanes_weather_final_5yr_EZ/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airplanes_weather_final_joins/","airplanes_weather_final_joins/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airplanes_weather_joins_intermediate/","airplanes_weather_joins_intermediate/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airplanes_weather_joins_intermediate_5yr_EZ/","airplanes_weather_joins_intermediate_5yr_EZ/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airportPercRank/","airportPercRank/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airportRanking/","airportRanking/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airportRankingFull/","airportRankingFull/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airport_locations/","airport_locations/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airport_locations_global/","airport_locations_global/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airport_weather_ref/","airport_weather_ref/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airport_weather_ref_full_dataset/","airport_weather_ref_full_dataset/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airport_weather_ref_full_dataset_new/","airport_weather_ref_full_dataset_new/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airport_weather_top5_ref/","airport_weather_top5_ref/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/airport_weather_top5_ref_full_dataset/","airport_weather_top5_ref_full_dataset/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/complete_join_6_month/","complete_join_6_month/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/df_airlines_rank/","df_airlines_rank/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/eda_set_time_of_day_zl_0402/","eda_set_time_of_day_zl_0402/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/eng_features/","eng_features/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/final_pgrankdelays_tod_yr/","final_pgrankdelays_tod_yr/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/flights_sel_jagan.delta/","flights_sel_jagan.delta/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/graph_test/","graph_test/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_data/","intermediate_5yr_airline_data/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_data_EZ/","intermediate_5yr_airline_data_EZ/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_with_delay_block/","intermediate_5yr_airline_with_delay_block/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_with_id/","intermediate_5yr_airline_with_id/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_with_id_EZ/","intermediate_5yr_airline_with_id_EZ/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_with_pgrank_EZ/","intermediate_5yr_airline_with_pgrank_EZ/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_with_roll90/","intermediate_5yr_airline_with_roll90/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_with_roll90_EZ/","intermediate_5yr_airline_with_roll90_EZ/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_with_seasons_wkday/","intermediate_5yr_airline_with_seasons_wkday/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_weather_cleaned_EZ/","intermediate_5yr_weather_cleaned_EZ/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_weather_cleaned_part_EZ/","intermediate_5yr_weather_cleaned_part_EZ/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/jairport_rank/","jairport_rank/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/mlpipeline_set_time_of_day_zl_0403/","mlpipeline_set_time_of_day_zl_0403/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/models/","models/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/ohe/","ohe/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/ohe-model/","ohe-model/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/pca/","pca/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/pca-model/","pca-model/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/pct_missing_weather/","pct_missing_weather/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/pgrank_investigation_time_of_day_and_delay/","pgrank_investigation_time_of_day_and_delay/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/pgrank_tod_conn/","pgrank_tod_conn/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/pgrank_tod_delay/","pgrank_tod_delay/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/pgrankdelays_tod_yr_after_coalesce_before_clean/","pgrankdelays_tod_yr_after_coalesce_before_clean/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/pgrankdelays_tod_yr_prior_to_coalesce/","pgrankdelays_tod_yr_prior_to_coalesce/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/pipeline/","pipeline/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/test/","test/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/test123/","test123/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/test1234/","test1234/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/test_weather/","test_weather/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/timezone/","timezone/",0],["wasbs://cemgr14c@cemgr14.blob.core.windows.net/weather_data_1d/","weather_data_1d/",0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_joins_sel/</td><td>airline_joins_sel/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_joins_sel.delta/</td><td>airline_joins_sel.delta/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_joins_sel_CEM/</td><td>airline_joins_sel_CEM/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_pr_cem.delta/</td><td>airline_pr_cem.delta/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_rank_CEM_CAR1.delta/</td><td>airline_rank_CEM_CAR1.delta/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_CEM_CAR1.delta/</td><td>airline_test_CEM_CAR1.delta/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_sel/</td><td>airline_test_sel/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_sel.delta/</td><td>airline_test_sel.delta/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_sel_CEM.delta/</td><td>airline_test_sel_CEM.delta/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_sel_CEM_CAR.delta/</td><td>airline_test_sel_CEM_CAR.delta/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_sel_CEM_CAR1.delta/</td><td>airline_test_sel_CEM_CAR1.delta/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_sel_CEM_carlos.delta/</td><td>airline_test_sel_CEM_carlos.delta/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airline_test_sel_jagan.delta/</td><td>airline_test_sel_jagan.delta/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airplanes_weather_final_5yr_EZ/</td><td>airplanes_weather_final_5yr_EZ/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airplanes_weather_final_joins/</td><td>airplanes_weather_final_joins/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airplanes_weather_joins_intermediate/</td><td>airplanes_weather_joins_intermediate/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airplanes_weather_joins_intermediate_5yr_EZ/</td><td>airplanes_weather_joins_intermediate_5yr_EZ/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airportPercRank/</td><td>airportPercRank/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airportRanking/</td><td>airportRanking/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airportRankingFull/</td><td>airportRankingFull/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airport_locations/</td><td>airport_locations/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airport_locations_global/</td><td>airport_locations_global/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airport_weather_ref/</td><td>airport_weather_ref/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airport_weather_ref_full_dataset/</td><td>airport_weather_ref_full_dataset/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airport_weather_ref_full_dataset_new/</td><td>airport_weather_ref_full_dataset_new/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airport_weather_top5_ref/</td><td>airport_weather_top5_ref/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/airport_weather_top5_ref_full_dataset/</td><td>airport_weather_top5_ref_full_dataset/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/complete_join_6_month/</td><td>complete_join_6_month/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/df_airlines_rank/</td><td>df_airlines_rank/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/eda_set_time_of_day_zl_0402/</td><td>eda_set_time_of_day_zl_0402/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/eng_features/</td><td>eng_features/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/final_pgrankdelays_tod_yr/</td><td>final_pgrankdelays_tod_yr/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/flights_sel_jagan.delta/</td><td>flights_sel_jagan.delta/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/graph_test/</td><td>graph_test/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_data/</td><td>intermediate_5yr_airline_data/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_data_EZ/</td><td>intermediate_5yr_airline_data_EZ/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_with_delay_block/</td><td>intermediate_5yr_airline_with_delay_block/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_with_id/</td><td>intermediate_5yr_airline_with_id/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_with_id_EZ/</td><td>intermediate_5yr_airline_with_id_EZ/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_with_pgrank_EZ/</td><td>intermediate_5yr_airline_with_pgrank_EZ/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_with_roll90/</td><td>intermediate_5yr_airline_with_roll90/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_with_roll90_EZ/</td><td>intermediate_5yr_airline_with_roll90_EZ/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_airline_with_seasons_wkday/</td><td>intermediate_5yr_airline_with_seasons_wkday/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_weather_cleaned_EZ/</td><td>intermediate_5yr_weather_cleaned_EZ/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/intermediate_5yr_weather_cleaned_part_EZ/</td><td>intermediate_5yr_weather_cleaned_part_EZ/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/jairport_rank/</td><td>jairport_rank/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/mlpipeline_set_time_of_day_zl_0403/</td><td>mlpipeline_set_time_of_day_zl_0403/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/models/</td><td>models/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/ohe/</td><td>ohe/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/ohe-model/</td><td>ohe-model/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/pca/</td><td>pca/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/pca-model/</td><td>pca-model/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/pct_missing_weather/</td><td>pct_missing_weather/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/pgrank_investigation_time_of_day_and_delay/</td><td>pgrank_investigation_time_of_day_and_delay/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/pgrank_tod_conn/</td><td>pgrank_tod_conn/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/pgrank_tod_delay/</td><td>pgrank_tod_delay/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/pgrankdelays_tod_yr_after_coalesce_before_clean/</td><td>pgrankdelays_tod_yr_after_coalesce_before_clean/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/pgrankdelays_tod_yr_prior_to_coalesce/</td><td>pgrankdelays_tod_yr_prior_to_coalesce/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/pipeline/</td><td>pipeline/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/test/</td><td>test/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/test123/</td><td>test123/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/test1234/</td><td>test1234/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/test_weather/</td><td>test_weather/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/timezone/</td><td>timezone/</td><td>0</td></tr><tr><td>wasbs://cemgr14c@cemgr14.blob.core.windows.net/weather_data_1d/</td><td>weather_data_1d/</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##Read data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03d9b370-ef8f-4140-9b6d-b971b7e98d9a"}}},{"cell_type":"code","source":["#read cleaned data with time of day, and other joined params that are useful for EDA/graphs\nfinal_df_clean_join4  = spark.read.parquet(f\"{blob_url}/eda_set_time_of_day_zl_0402\") \nfinal_df_clean_join4  = final_df_clean_join4.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c82c03ec-b1e3-489b-9fcc-4ac26efcb17f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["final_df_clean_join5 = final_df_clean_join4.dropna()\nfinal_df_clean_join4.unpersist()\nfinal_df_clean_join5 = final_df_clean_join5.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f8c243d5-26cc-4c1b-a633-052302f1d732"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["airportRankingFull = spark.read.parquet(f\"{blob_url}/airportRankingFull\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4bc3be2d-57bf-48b8-a1a6-400e6b0b8107"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["display(airportRankingFull.limit(5))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4ac6bfb9-baa2-4523-8963-63555d2e146f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[15249,9.792927943900586E-4,4,19343,8.548845294326957E-4,204149.0,"72214093805",30.396499633789062,-84.35030364990234,30.393,-84.353,0.46723855313196216,"America/New_York",1],[11097,5.767268232368813E-4,2,3270,5.34982115131496E-4,35680.0,"72670024045",44.520198822,-109.024002075,44.517,-109.017,0.6593297865406805,"America/Denver",1],[14877,0.0018938967099701653,1,923,0.0017400841202419555,23746.0,"72458603919",38.79100036621094,-97.6521987915039,38.8,-97.65,1.018694889517569,"America/Chicago",1],[11721,9.326734413421367E-4,5,16327,8.596435037470942E-4,183799.0,"72637014826",42.96540069580078,-83.74359893798828,42.967,-83.749,0.47408860931317376,"America/New_York",1],[13029,7.967300988846184E-4,3,11132,7.459403848987206E-4,144174.0,"72551014939",40.85100173950195,-96.75920104980469,40.851,-96.748,0.9421124991815832,"America/Chicago",1]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"airport","type":"\"long\"","metadata":"{}"},{"name":"Connec_Ranking","type":"\"double\"","metadata":"{}"},{"name":"N_Air_to","type":"\"long\"","metadata":"{}"},{"name":"Num_connection","type":"\"long\"","metadata":"{}"},{"name":"Delay_Ranking","type":"\"double\"","metadata":"{}"},{"name":"Amt_Delay","type":"\"double\"","metadata":"{}"},{"name":"station_id","type":"\"string\"","metadata":"{}"},{"name":"air_lat","type":"\"double\"","metadata":"{}"},{"name":"air_lon","type":"\"double\"","metadata":"{}"},{"name":"st_lat","type":"\"double\"","metadata":"{}"},{"name":"st_lon","type":"\"double\"","metadata":"{}"},{"name":"dist_km","type":"\"double\"","metadata":"{}"},{"name":"time_zone","type":"\"string\"","metadata":"{}"},{"name":"rnk","type":"\"integer\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>airport</th><th>Connec_Ranking</th><th>N_Air_to</th><th>Num_connection</th><th>Delay_Ranking</th><th>Amt_Delay</th><th>station_id</th><th>air_lat</th><th>air_lon</th><th>st_lat</th><th>st_lon</th><th>dist_km</th><th>time_zone</th><th>rnk</th></tr></thead><tbody><tr><td>15249</td><td>9.792927943900586E-4</td><td>4</td><td>19343</td><td>8.548845294326957E-4</td><td>204149.0</td><td>72214093805</td><td>30.396499633789062</td><td>-84.35030364990234</td><td>30.393</td><td>-84.353</td><td>0.46723855313196216</td><td>America/New_York</td><td>1</td></tr><tr><td>11097</td><td>5.767268232368813E-4</td><td>2</td><td>3270</td><td>5.34982115131496E-4</td><td>35680.0</td><td>72670024045</td><td>44.520198822</td><td>-109.024002075</td><td>44.517</td><td>-109.017</td><td>0.6593297865406805</td><td>America/Denver</td><td>1</td></tr><tr><td>14877</td><td>0.0018938967099701653</td><td>1</td><td>923</td><td>0.0017400841202419555</td><td>23746.0</td><td>72458603919</td><td>38.79100036621094</td><td>-97.6521987915039</td><td>38.8</td><td>-97.65</td><td>1.018694889517569</td><td>America/Chicago</td><td>1</td></tr><tr><td>11721</td><td>9.326734413421367E-4</td><td>5</td><td>16327</td><td>8.596435037470942E-4</td><td>183799.0</td><td>72637014826</td><td>42.96540069580078</td><td>-83.74359893798828</td><td>42.967</td><td>-83.749</td><td>0.47408860931317376</td><td>America/New_York</td><td>1</td></tr><tr><td>13029</td><td>7.967300988846184E-4</td><td>3</td><td>11132</td><td>7.459403848987206E-4</td><td>144174.0</td><td>72551014939</td><td>40.85100173950195</td><td>-96.75920104980469</td><td>40.851</td><td>-96.748</td><td>0.9421124991815832</td><td>America/Chicago</td><td>1</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["airport_select = airportRankingFull.select('airport','Delay_Ranking').withColumn('airport_id_int',col('airport').cast(IntegerType())).drop('airport')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5feecf59-7112-4d1b-92e2-e6d360e16f7f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["cond12 = [(final_df_clean_join5.ORIGIN_AIRPORT_ID == airport_select.airport_id_int)]\nfinal_df_clean_join5 = final_df_clean_join5.join(airport_select, cond12, 'leftouter')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de7444ad-18b3-4169-93ba-c215f3b9ce7b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1731553363149756&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> cond12 <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">(</span>final_df_clean_join5<span class=\"ansi-blue-fg\">.</span>ORIGIN_AIRPORT_ID <span class=\"ansi-blue-fg\">==</span> airport_select<span class=\"ansi-blue-fg\">.</span>airport_id_int<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>final_df_clean_join5 <span class=\"ansi-blue-fg\">=</span> final_df_clean_join5<span class=\"ansi-blue-fg\">.</span>join<span class=\"ansi-blue-fg\">(</span>airport_select<span class=\"ansi-blue-fg\">,</span> cond12<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#39;leftouter&#39;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">join</span><span class=\"ansi-blue-fg\">(self, other, on, how)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1360</span>                 on <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jseq<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1361</span>             <span class=\"ansi-green-fg\">assert</span> isinstance<span class=\"ansi-blue-fg\">(</span>how<span class=\"ansi-blue-fg\">,</span> str<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;how should be a string&#34;</span>\n<span class=\"ansi-green-fg\">-&gt; 1362</span><span class=\"ansi-red-fg\">             </span>jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>join<span class=\"ansi-blue-fg\">(</span>other<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">,</span> on<span class=\"ansi-blue-fg\">,</span> how<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1363</span>         <span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>jdf<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1364</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: Column airport_id_int#5074 are ambiguous. It&#39;s probably because you joined several Datasets together, and some of these Datasets are the same. This column points to one of the Datasets but Spark is unable to figure out which one. Please alias the Datasets with different names via `Dataset.as` before joining them, and specify the column using qualified name, e.g. `df.as(&#34;a&#34;).join(df.as(&#34;b&#34;), $&#34;a.id&#34; &gt; $&#34;b.id&#34;)`. You can also set spark.sql.analyzer.failAmbiguousSelfJoin to false to disable this check.</div>","errorSummary":"<span class=\"ansi-red-fg\">AnalysisException</span>: Column airport_id_int#5074 are ambiguous. It&#39;s probably because you joined several Datasets together, and some of these Datasets are the same. This column points to one of the Datasets but Spark is unable to figure out which one. Please alias the Datasets with different names via `Dataset.as` before joining them, and specify the column using qualified name, e.g. `df.as(&#34;a&#34;).join(df.as(&#34;b&#34;), $&#34;a.id&#34; &gt; $&#34;b.id&#34;)`. You can also set spark.sql.analyzer.failAmbiguousSelfJoin to false to disable this check.","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1731553363149756&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> cond12 <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">(</span>final_df_clean_join5<span class=\"ansi-blue-fg\">.</span>ORIGIN_AIRPORT_ID <span class=\"ansi-blue-fg\">==</span> airport_select<span class=\"ansi-blue-fg\">.</span>airport_id_int<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>final_df_clean_join5 <span class=\"ansi-blue-fg\">=</span> final_df_clean_join5<span class=\"ansi-blue-fg\">.</span>join<span class=\"ansi-blue-fg\">(</span>airport_select<span class=\"ansi-blue-fg\">,</span> cond12<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#39;leftouter&#39;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">join</span><span class=\"ansi-blue-fg\">(self, other, on, how)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1360</span>                 on <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jseq<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1361</span>             <span class=\"ansi-green-fg\">assert</span> isinstance<span class=\"ansi-blue-fg\">(</span>how<span class=\"ansi-blue-fg\">,</span> str<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;how should be a string&#34;</span>\n<span class=\"ansi-green-fg\">-&gt; 1362</span><span class=\"ansi-red-fg\">             </span>jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>join<span class=\"ansi-blue-fg\">(</span>other<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">,</span> on<span class=\"ansi-blue-fg\">,</span> how<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1363</span>         <span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>jdf<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1364</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: Column airport_id_int#5074 are ambiguous. It&#39;s probably because you joined several Datasets together, and some of these Datasets are the same. This column points to one of the Datasets but Spark is unable to figure out which one. Please alias the Datasets with different names via `Dataset.as` before joining them, and specify the column using qualified name, e.g. `df.as(&#34;a&#34;).join(df.as(&#34;b&#34;), $&#34;a.id&#34; &gt; $&#34;b.id&#34;)`. You can also set spark.sql.analyzer.failAmbiguousSelfJoin to false to disable this check.</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Percent Rank\n \nfinal_df_clean_join6 = final_df_clean_join5.select(\"ORIGIN_AIRPORT_ID\",\"DEST_AIRPORT_ID\",\"Airport_Name_O\",\"Airport_Name_D\",\"Delay_Ranking\", F.percent_rank().over(Window.partitionBy().orderBy(final_df_clean_join5['Delay_Ranking'])).alias(\"delay_percent_rank\"))\nfinal_df_clean_join6 = final_df_clean_join6.withColumn('relationship',lit('flying_to')).withColumnRenamed('ORIGIN_AIRPORT_ID','src').withColumnRenamed('DEST_AIRPORT_ID','dst')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"95f95b6d-a812-4b02-beee-4250dd5b2671"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["final_df_clean_join6 = final_df_clean_join6.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e3cd74a4-377e-4d8b-be3b-e34df35db1f9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["final_df_clean_join6 = final_df_clean_join6.withColumn('delay_percent_rank_float',col('delay_percent_rank').cast(FloatType()))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d5e7a8c8-4124-4854-aec6-b738497121c6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["\ndef delay_rank_buckets(perc_rank):\n  label = None\n  if perc_rank <= (1/3):\n    label = 'low_delay'\n  elif perc_rank <= (2/3) and perc_rank>(1/3):\n    label ='moderately_delay'\n  elif perc_rank<=1 and perc_rank>(2/3):\n    label = 'high_delay'\n  else:\n    pass\n  return label\n\nextract_delay_rank_buckets_udf = udf(delay_rank_buckets)\nfinal_df_clean_join6 = final_df_clean_join6.withColumn(\"delay_rank_buckets_col\", extract_delay_rank_buckets_udf(\"delay_percent_rank_float\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f8b8eb1-7794-44c3-99f0-0689b787cc88"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["final_df_clean_join6.select(\"delay_rank_buckets_col\").distinct().show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa858cae-b675-42b7-a121-d80ab3f182db"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------------------+\n|delay_rank_buckets_col|\n+----------------------+\n|            high_delay|\n|             low_delay|\n|      moderately_delay|\n+----------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------+\ndelay_rank_buckets_col|\n+----------------------+\n            high_delay|\n             low_delay|\n      moderately_delay|\n+----------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Graph Implementation and Experiments"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"27af9aea-a94f-429f-aa0c-4069b9bc85bf"}}},{"cell_type":"markdown","source":["## Community Detection Algorithms"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a569f06-4a23-45d6-8aad-bcd70910e55e"}}},{"cell_type":"markdown","source":["In this section, we would like to experiment on using Strongly Connected Components and Label Propagation to find clusters of airports with high connectivity and traffic that may propagate delays or be exposed to similar weather patterns.\n\nLabel Propagation quickly infers groups based on node labels. \nStrongly Connected components identifies connected clusters."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21f5b183-967e-4661-8a5d-a61b5944c72e"}}},{"cell_type":"markdown","source":["The Label Propagation algorithm (LPA) is a fast algorithm for finding communities\nin a graph. In LPA, nodes select their group based on their direct neighbors. This process is well suited to networks where groupings are less clear and weights can be used\nto help a node determine which community to place itself within. It also lends itself\nwell to semisupervised learning because you can seed the process with preassigned,\nindicative node labels."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e789c384-894f-405b-bbd9-a65825debc9a"}}},{"cell_type":"markdown","source":["The steps often used for the Label Propagation pull method are:\n1. Every node is initialized with a unique label (an identifier), and, optionally pre\nliminary seed labels can be used.\n2. These labels propagate through the network.\n3. At every propagation iteration, each node updates its label to match the one with\nthe maximum weight, which is calculated based on the weights of neighbor nodes\nand their relationships. Ties are broken uniformly and randomly.\n4. LPA reaches convergence when each node has the majority label of its neighbors\n\nAs labels propagate, densely connected groups of nodes quickly reach a consensus on\na unique label. At the end of the propagation, only a few labels will remain, and nodes\nthat have the same label belong to the same community."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bbcd233f-10d3-4108-afd6-914687c64d79"}}},{"cell_type":"code","source":["v = final_df_clean_join6.select('src','Airport_Name_O','delay_percent_rank_float')\nv = v.withColumnRenamed('src','id').withColumnRenamed('Airport_Name_O','name')\nvertices = v\n\ne = final_df_clean_join6.select('src','dst','delay_rank_buckets_col')\ne = e.withColumnRenamed('delay_rank_buckets_col','relationship')\n#e = final_df_clean_join6.select('src','dst','relationship')\n\nedges = e\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69c6f4b4-71f4-4212-a4c1-32ce18ef4900"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["g = GraphFrame(vertices, edges)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"28455a43-92bf-4633-b05c-5a49e091a61d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["result = g.labelPropagation(maxIter=5)\ndisplay(result)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f26f0904-c19b-423f-be58-8741620f7222"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1731553363150299&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>result <span class=\"ansi-blue-fg\">=</span> g<span class=\"ansi-blue-fg\">.</span>labelPropagation<span class=\"ansi-blue-fg\">(</span>maxIter<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">5</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> display<span class=\"ansi-blue-fg\">(</span>result<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-c532992f-edc0-4673-a346-3d43997679c7/userFiles-651e0087-3e59-4ee3-a275-e8bde91f74ec/addedFile7831133416840271778graphframes_0_8_2_spark3_1_s_2_12-8cacf.jar/graphframes/graphframe.py</span> in <span class=\"ansi-cyan-fg\">labelPropagation</span><span class=\"ansi-blue-fg\">(self, maxIter)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    341</span>         <span class=\"ansi-blue-fg\">:</span><span class=\"ansi-green-fg\">return</span><span class=\"ansi-blue-fg\">:</span> DataFrame <span class=\"ansi-green-fg\">with</span> new vertices column <span class=\"ansi-blue-fg\">&#34;label&#34;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    342</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 343</span><span class=\"ansi-red-fg\">         </span>jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jvm_graph<span class=\"ansi-blue-fg\">.</span>labelPropagation<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>maxIter<span class=\"ansi-blue-fg\">(</span>maxIter<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>run<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    344</span>         <span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>jdf<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_sqlContext<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    345</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    116</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 117</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    119</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    324</span>             value <span class=\"ansi-blue-fg\">=</span> OUTPUT_CONVERTER<span class=\"ansi-blue-fg\">[</span>type<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">(</span>answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">if</span> answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">==</span> REFERENCE_TYPE<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 326</span><span class=\"ansi-red-fg\">                 raise Py4JJavaError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    328</span>                     format(target_id, &#34;.&#34;, name), value)\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o4061.run.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 74.0 failed 4 times, most recent failure: Lost task 0.3 in stage 74.0 (TID 1952) (10.139.64.84 executor 31): ExecutorLostFailure (executor 31 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 168905 ms\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2828)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2775)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2769)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2769)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1305)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1305)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1305)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3036)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2977)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2965)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1067)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2477)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2460)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2572)\n\tat org.apache.spark.rdd.RDD.$anonfun$fold$1(RDD.scala:1193)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:419)\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1187)\n\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:96)\n\tat org.apache.spark.graphx.Pregel$.apply(Pregel.scala:140)\n\tat org.apache.spark.graphx.lib.LabelPropagation$.run(LabelPropagation.scala:68)\n\tat org.graphframes.lib.LabelPropagation$.org$graphframes$lib$LabelPropagation$$run(LabelPropagation.scala:62)\n\tat org.graphframes.lib.LabelPropagation.run(LabelPropagation.scala:55)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>","errorSummary":"org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 74.0 failed 4 times, most recent failure: Lost task 0.3 in stage 74.0 (TID 1952) (10.139.64.84 executor 31): ExecutorLostFailure (executor 31 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 168905 ms","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1731553363150299&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>result <span class=\"ansi-blue-fg\">=</span> g<span class=\"ansi-blue-fg\">.</span>labelPropagation<span class=\"ansi-blue-fg\">(</span>maxIter<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">5</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> display<span class=\"ansi-blue-fg\">(</span>result<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-c532992f-edc0-4673-a346-3d43997679c7/userFiles-651e0087-3e59-4ee3-a275-e8bde91f74ec/addedFile7831133416840271778graphframes_0_8_2_spark3_1_s_2_12-8cacf.jar/graphframes/graphframe.py</span> in <span class=\"ansi-cyan-fg\">labelPropagation</span><span class=\"ansi-blue-fg\">(self, maxIter)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    341</span>         <span class=\"ansi-blue-fg\">:</span><span class=\"ansi-green-fg\">return</span><span class=\"ansi-blue-fg\">:</span> DataFrame <span class=\"ansi-green-fg\">with</span> new vertices column <span class=\"ansi-blue-fg\">&#34;label&#34;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    342</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 343</span><span class=\"ansi-red-fg\">         </span>jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jvm_graph<span class=\"ansi-blue-fg\">.</span>labelPropagation<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>maxIter<span class=\"ansi-blue-fg\">(</span>maxIter<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>run<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    344</span>         <span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>jdf<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_sqlContext<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    345</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    116</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 117</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    119</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    324</span>             value <span class=\"ansi-blue-fg\">=</span> OUTPUT_CONVERTER<span class=\"ansi-blue-fg\">[</span>type<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">(</span>answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">if</span> answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">==</span> REFERENCE_TYPE<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 326</span><span class=\"ansi-red-fg\">                 raise Py4JJavaError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    328</span>                     format(target_id, &#34;.&#34;, name), value)\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o4061.run.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 74.0 failed 4 times, most recent failure: Lost task 0.3 in stage 74.0 (TID 1952) (10.139.64.84 executor 31): ExecutorLostFailure (executor 31 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 168905 ms\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2828)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2775)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2769)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2769)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1305)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1305)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1305)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3036)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2977)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2965)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1067)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2477)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2460)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2572)\n\tat org.apache.spark.rdd.RDD.$anonfun$fold$1(RDD.scala:1193)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:419)\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1187)\n\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:96)\n\tat org.apache.spark.graphx.Pregel$.apply(Pregel.scala:140)\n\tat org.apache.spark.graphx.lib.LabelPropagation$.run(LabelPropagation.scala:68)\n\tat org.graphframes.lib.LabelPropagation$.org$graphframes$lib$LabelPropagation$$run(LabelPropagation.scala:62)\n\tat org.graphframes.lib.LabelPropagation.run(LabelPropagation.scala:55)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.write.parquet(f\"{blob_url}/lpa_result\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"927861da-1728-4b2b-9cbc-acf5b96ed10f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1731553363150691&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>result<span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">.</span>parquet<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#34;{blob_url}/lpa_result&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;result&#39; is not defined</div>","errorSummary":"<span class=\"ansi-red-fg\">NameError</span>: name &#39;result&#39; is not defined","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1731553363150691&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>result<span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">.</span>parquet<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#34;{blob_url}/lpa_result&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;result&#39; is not defined</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["###Strongly Connected Components"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14507b5f-488b-4570-b5e4-13cdeb9eabf5"}}},{"cell_type":"code","source":["result2 = g.stronglyConnectedComponents(maxIter=10)\ndisplay(result2.select(\"id\", \"component\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a8f4bb81-a6e1-470f-80b1-99e9a538a85f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1731553363148451&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>result2 <span class=\"ansi-blue-fg\">=</span> g<span class=\"ansi-blue-fg\">.</span>stronglyConnectedComponents<span class=\"ansi-blue-fg\">(</span>maxIter<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">10</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> display<span class=\"ansi-blue-fg\">(</span>result2<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;id&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;component&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-c532992f-edc0-4673-a346-3d43997679c7/userFiles-651e0087-3e59-4ee3-a275-e8bde91f74ec/addedFile7831133416840271778graphframes_0_8_2_spark3_1_s_2_12-8cacf.jar/graphframes/graphframe.py</span> in <span class=\"ansi-cyan-fg\">stronglyConnectedComponents</span><span class=\"ansi-blue-fg\">(self, maxIter)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    416</span>         <span class=\"ansi-blue-fg\">:</span><span class=\"ansi-green-fg\">return</span><span class=\"ansi-blue-fg\">:</span> DataFrame <span class=\"ansi-green-fg\">with</span> new vertex column <span class=\"ansi-blue-fg\">&#34;component&#34;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    417</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 418</span><span class=\"ansi-red-fg\">         </span>jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jvm_graph<span class=\"ansi-blue-fg\">.</span>stronglyConnectedComponents<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>maxIter<span class=\"ansi-blue-fg\">(</span>maxIter<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>run<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    419</span>         <span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>jdf<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_sqlContext<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    420</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    116</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 117</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    119</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    324</span>             value <span class=\"ansi-blue-fg\">=</span> OUTPUT_CONVERTER<span class=\"ansi-blue-fg\">[</span>type<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">(</span>answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">if</span> answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">==</span> REFERENCE_TYPE<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 326</span><span class=\"ansi-red-fg\">                 raise Py4JJavaError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    328</span>                     format(target_id, &#34;.&#34;, name), value)\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o15935.run.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 198.1 failed 4 times, most recent failure: Lost task 0.3 in stage 198.1 (TID 1971) (10.139.64.79 executor 35): java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.graphx.impl.EdgePartitionBuilder.toEdgePartition(EdgePartitionBuilder.scala:42)\n\tat org.apache.spark.graphx.EdgeRDD$.$anonfun$fromEdges$1(EdgeRDD.scala:110)\n\tat org.apache.spark.graphx.EdgeRDD$.$anonfun$fromEdges$1$adapted(EdgeRDD.scala:105)\n\tat org.apache.spark.graphx.EdgeRDD$$$Lambda$1266/1335849522.apply(Unknown Source)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:920)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:920)\n\tat org.apache.spark.rdd.RDD$$Lambda$1267/1950984248.apply(Unknown Source)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:380)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:344)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:380)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:393)\n\tat org.apache.spark.rdd.RDD$$Lambda$1306/237397819.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1430)\n\tat org.apache.spark.storage.BlockManager$$Lambda$788/308867270.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1357)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1421)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1240)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:391)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:342)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:380)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:393)\n\tat org.apache.spark.rdd.RDD$$Lambda$1306/237397819.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1430)\n\tat org.apache.spark.storage.BlockManager$$Lambda$788/308867270.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1357)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1421)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1240)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:391)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:342)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2828)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2775)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2769)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2769)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1305)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1305)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1305)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3036)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2977)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2965)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1067)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2477)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2460)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2572)\n\tat org.apache.spark.rdd.RDD.$anonfun$fold$1(RDD.scala:1193)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:419)\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1187)\n\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:96)\n\tat org.apache.spark.graphx.lib.StronglyConnectedComponents$.run(StronglyConnectedComponents.scala:72)\n\tat org.graphframes.lib.StronglyConnectedComponents$.org$graphframes$lib$StronglyConnectedComponents$$run(StronglyConnectedComponents.scala:51)\n\tat org.graphframes.lib.StronglyConnectedComponents.run(StronglyConnectedComponents.scala:43)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.graphx.impl.EdgePartitionBuilder.toEdgePartition(EdgePartitionBuilder.scala:42)\n\tat org.apache.spark.graphx.EdgeRDD$.$anonfun$fromEdges$1(EdgeRDD.scala:110)\n\tat org.apache.spark.graphx.EdgeRDD$.$anonfun$fromEdges$1$adapted(EdgeRDD.scala:105)\n\tat org.apache.spark.graphx.EdgeRDD$$$Lambda$1266/1335849522.apply(Unknown Source)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:920)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:920)\n\tat org.apache.spark.rdd.RDD$$Lambda$1267/1950984248.apply(Unknown Source)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:380)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:344)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:380)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:393)\n\tat org.apache.spark.rdd.RDD$$Lambda$1306/237397819.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1430)\n\tat org.apache.spark.storage.BlockManager$$Lambda$788/308867270.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1357)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1421)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1240)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:391)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:342)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:380)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:393)\n\tat org.apache.spark.rdd.RDD$$Lambda$1306/237397819.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1430)\n\tat org.apache.spark.storage.BlockManager$$Lambda$788/308867270.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1357)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1421)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1240)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:391)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:342)\n</div>","errorSummary":"org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 198.1 failed 4 times, most recent failure: Lost task 0.3 in stage 198.1 (TID 1971) (10.139.64.79 executor 35): java.lang.OutOfMemoryError: Java heap space","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1731553363148451&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>result2 <span class=\"ansi-blue-fg\">=</span> g<span class=\"ansi-blue-fg\">.</span>stronglyConnectedComponents<span class=\"ansi-blue-fg\">(</span>maxIter<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">10</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> display<span class=\"ansi-blue-fg\">(</span>result2<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;id&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;component&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/local_disk0/spark-c532992f-edc0-4673-a346-3d43997679c7/userFiles-651e0087-3e59-4ee3-a275-e8bde91f74ec/addedFile7831133416840271778graphframes_0_8_2_spark3_1_s_2_12-8cacf.jar/graphframes/graphframe.py</span> in <span class=\"ansi-cyan-fg\">stronglyConnectedComponents</span><span class=\"ansi-blue-fg\">(self, maxIter)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    416</span>         <span class=\"ansi-blue-fg\">:</span><span class=\"ansi-green-fg\">return</span><span class=\"ansi-blue-fg\">:</span> DataFrame <span class=\"ansi-green-fg\">with</span> new vertex column <span class=\"ansi-blue-fg\">&#34;component&#34;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    417</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 418</span><span class=\"ansi-red-fg\">         </span>jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jvm_graph<span class=\"ansi-blue-fg\">.</span>stronglyConnectedComponents<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>maxIter<span class=\"ansi-blue-fg\">(</span>maxIter<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>run<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    419</span>         <span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>jdf<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_sqlContext<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    420</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    116</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 117</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    119</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    324</span>             value <span class=\"ansi-blue-fg\">=</span> OUTPUT_CONVERTER<span class=\"ansi-blue-fg\">[</span>type<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">(</span>answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">if</span> answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">==</span> REFERENCE_TYPE<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 326</span><span class=\"ansi-red-fg\">                 raise Py4JJavaError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    328</span>                     format(target_id, &#34;.&#34;, name), value)\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o15935.run.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 198.1 failed 4 times, most recent failure: Lost task 0.3 in stage 198.1 (TID 1971) (10.139.64.79 executor 35): java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.graphx.impl.EdgePartitionBuilder.toEdgePartition(EdgePartitionBuilder.scala:42)\n\tat org.apache.spark.graphx.EdgeRDD$.$anonfun$fromEdges$1(EdgeRDD.scala:110)\n\tat org.apache.spark.graphx.EdgeRDD$.$anonfun$fromEdges$1$adapted(EdgeRDD.scala:105)\n\tat org.apache.spark.graphx.EdgeRDD$$$Lambda$1266/1335849522.apply(Unknown Source)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:920)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:920)\n\tat org.apache.spark.rdd.RDD$$Lambda$1267/1950984248.apply(Unknown Source)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:380)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:344)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:380)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:393)\n\tat org.apache.spark.rdd.RDD$$Lambda$1306/237397819.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1430)\n\tat org.apache.spark.storage.BlockManager$$Lambda$788/308867270.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1357)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1421)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1240)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:391)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:342)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:380)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:393)\n\tat org.apache.spark.rdd.RDD$$Lambda$1306/237397819.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1430)\n\tat org.apache.spark.storage.BlockManager$$Lambda$788/308867270.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1357)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1421)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1240)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:391)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:342)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2828)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2775)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2769)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2769)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1305)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1305)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1305)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3036)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2977)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2965)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1067)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2477)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2460)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2572)\n\tat org.apache.spark.rdd.RDD.$anonfun$fold$1(RDD.scala:1193)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:125)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:419)\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1187)\n\tat org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:96)\n\tat org.apache.spark.graphx.lib.StronglyConnectedComponents$.run(StronglyConnectedComponents.scala:72)\n\tat org.graphframes.lib.StronglyConnectedComponents$.org$graphframes$lib$StronglyConnectedComponents$$run(StronglyConnectedComponents.scala:51)\n\tat org.graphframes.lib.StronglyConnectedComponents.run(StronglyConnectedComponents.scala:43)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.graphx.impl.EdgePartitionBuilder.toEdgePartition(EdgePartitionBuilder.scala:42)\n\tat org.apache.spark.graphx.EdgeRDD$.$anonfun$fromEdges$1(EdgeRDD.scala:110)\n\tat org.apache.spark.graphx.EdgeRDD$.$anonfun$fromEdges$1$adapted(EdgeRDD.scala:105)\n\tat org.apache.spark.graphx.EdgeRDD$$$Lambda$1266/1335849522.apply(Unknown Source)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:920)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:920)\n\tat org.apache.spark.rdd.RDD$$Lambda$1267/1950984248.apply(Unknown Source)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:380)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:344)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:380)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:393)\n\tat org.apache.spark.rdd.RDD$$Lambda$1306/237397819.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1430)\n\tat org.apache.spark.storage.BlockManager$$Lambda$788/308867270.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1357)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1421)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1240)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:391)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:342)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:380)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:393)\n\tat org.apache.spark.rdd.RDD$$Lambda$1306/237397819.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1430)\n\tat org.apache.spark.storage.BlockManager$$Lambda$788/308867270.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1357)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1421)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1240)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:391)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:342)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result2.write.parquet(f\"{blob_url}/scc_result\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"025c7154-b07d-4dd6-a238-c6479438f411"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1731553363150697&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>result2<span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">.</span>parquet<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#34;{blob_url}/scc_result&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;result2&#39; is not defined</div>","errorSummary":"<span class=\"ansi-red-fg\">NameError</span>: name &#39;result2&#39; is not defined","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1731553363150697&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>result2<span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">.</span>parquet<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#34;{blob_url}/scc_result&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;result2&#39; is not defined</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Centrality Algorithms"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2897e4e6-8445-468b-ad1b-a00266120db1"}}},{"cell_type":"markdown","source":["Centrality algorithms help identify influential points in a flight network that impact the flow of transport Apply Closeness Centrality when you need to know which nodes disseminate things the fastest. Using weighted relationships can be especially helpful in evaluating interaction speeds in communication and behavioral analyses. Implement this with ApacheSpark and GraphFrames\n\nThe goal here is to estimate delays in flight departure to the target destination and to examine how delays propagate through paths and airport communities.\nThe expected result is to see a table with Col 1 :Airport names, Col 2: Connected Airport Names and closeness metric. If score is 1.0 then each directly connects to all nodes in their part of the graph. Even if an airport has few connections, if score is 1.0 it means the airport has close influence on those connected airports."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"29b1072c-9c29-4dbc-ac64-53b5bd0d468d"}}},{"cell_type":"code","source":["final_df_clean_join4  = spark.read.parquet(f\"{blob_url}/eda_set_time_of_day_zl_0402\") \nfinal_df_clean_join4 = final_df_clean_join4.cache()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c324c0ad-00f4-4463-bcf4-b32360f75487"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["v = final_df_clean_join4.select(\"Airport_Name_O\",\"air_lat_O\", \"air_lon_O\",\"Air_Page_Rank_traffic\").withColumnRenamed(\"Airport_Name_O\" ,\"id\").withColumnRenamed(\"air_lat_O\" ,\"latitude\").withColumnRenamed(\"air_lon_O\" ,\"longitude\").withColumnRenamed(\"Air_Page_Rank_traffic\",\"traffic\")\ne = final_df_clean_join4.select(\"Airport_Name_O\",\"Airport_Name_D\",\"Air_Page_Rank_traffic\",\"DISTANCE\",\"trip_id\").withColumnRenamed(\"Airport_Name_O\",\"src\").withColumnRenamed(\"Airport_Name_D\",\"dst\").withColumnRenamed(\"Air_Page_Rank_traffic\",\"cost\").withColumnRenamed(\"DISTANCE\" ,\"distance\").withColumnRenamed(\"trip_id\" ,\"id\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24028346-267a-47db-a7eb-e41f129fde0f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Pg104 \n\ndef collect_paths(paths):\n  return F.collect_set(paths)\n\ncollect_paths_udf = F.udf(collect_paths, ArrayType(StringType()))\n\npaths_type = ArrayType(StructType([StructField(\"id\", StringType()), StructField(\"distance\",FloatType())]))\n\ndef flatten(ids):\n  flat_list = [item for sublist in ids for item in sublist]\n  return list(dict(sorted(flat_list, key=itemgetter(0))).items())\n\nflatten_udf = F.udf(flatten, paths_type)\n\ndef new_paths(paths, id):\n  paths = [{\"id\": col1, \"distance\": col2 + 1} for col1,col2 in paths if col1 != id]\n  paths.append({\"id\": id, \"distance\": 1})\n  return paths\n\nnew_paths_udf = F.udf(new_paths, paths_type)\n\ndef merge_paths(ids, new_ids, id):\n  joined_ids = ids + (new_ids if new_ids else [])\n  merged_ids = [(col1, col2) for col1, col2 in joined_ids if col1 != id]\n  best_ids = dict(sorted(merged_ids, key=itemgetter(1), reverse=True))\n  return [{\"id\": col1, \"distance\": col2} for col1, col2 in best_ids.items()]\n\nmerge_paths_udf = F.udf(merge_paths, paths_type)\n\ndef calculate_closeness(ids):\n  nodes = len(ids)\n  total_distance = sum([col2 for col1, col2 in ids])\n  return 0 if total_distance == 0 else nodes * 1.0 / total_distance\n\ncloseness_udf = F.udf(calculate_closeness, DoubleType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ce929cc4-93cf-444b-99e8-e1edf9efef71"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#This ran for 16 hours and ran into a timeout error\n\n#Pg 105\n\nvertices = final_df_clean_join4.select(\"Airport_Name_O\",\"air_lat_O\", \"air_lon_O\",\"Air_Page_Rank_traffic\").withColumnRenamed(\"Airport_Name_O\" ,\"id\").withColumnRenamed(\"air_lat_O\" ,\"latitude\").withColumnRenamed(\"air_lon_O\" ,\"longitude\").withColumnRenamed(\"Air_Page_Rank_traffic\",\"traffic\")\nedges = final_df_clean_join4.select(\"Airport_Name_O\",\"Airport_Name_D\",\"Air_Page_Rank_traffic\",\"DISTANCE\",\"trip_id\").withColumnRenamed(\"Airport_Name_O\",\"src\").withColumnRenamed(\"Airport_Name_D\",\"dst\").withColumnRenamed(\"Air_Page_Rank_traffic\",\"cost\").withColumnRenamed(\"DISTANCE\" ,\"distance\")\n\ng = GraphFrame(vertices,edges)\nvertices = g.vertices.withColumn(\"ids\", F.array())\ncached_vertices = AM.getCachedDataFrame(vertices)\ng2 = GraphFrame(cached_vertices, g.edges)\n\n\n\nfor i in range(0, g2.vertices.count()):\n  msg_dst = new_paths_udf(AM.src[\"ids\"], AM.src[\"id\"])\n  msg_src = new_paths_udf(AM.dst[\"ids\"], AM.dst[\"id\"])\n  agg = g2.aggregateMessages(F.collect_set(AM.msg).alias(\"agg\"),sendToSrc=msg_src, sendToDst=msg_dst)\n  res = agg.withColumn(\"newIds\", flatten_udf(\"agg\")).drop(\"agg\")\n  new_vertices = (g2.vertices.join(res, on=\"id\", how=\"left_outer\").withColumn(\"mergedIds\", merge_paths_udf(\"ids\", \"newIds\",\"id\")).drop(\"ids\", \"newIds\").withColumnRenamed(\"mergedIds\", \"ids\"))\n  cached_new_vertices = AM.getCachedDataFrame(new_vertices)\n  g2 = GraphFrame(cached_new_vertices, g2.edges)\n\n  \n(g2.vertices.withColumn(\"closeness\", closeness_udf(\"ids\")).sort(\"closeness\", ascending=False).show(truncate=False))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5b99bb3-e28c-4b9e-8041-d7c40913fe58"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### References:\n\n- https://go.neo4j.com/rs/710-RRC-335/images/Neo4j_Graph_Algorithms.pdf, Pg 104-105, Pg 139, Pg 146\n\n- https://graphframes.github.io/graphframes/docs/_site/user-guide.html\n\n- https://docs.databricks.com/_static/notebooks/graphframes-user-guide-py.html"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f1162703-9d1c-4f80-846d-4efff8c6dfe6"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Exploration and Graphs with Pyspark and GraphFrames","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1858507102417339}},"nbformat":4,"nbformat_minor":0}
